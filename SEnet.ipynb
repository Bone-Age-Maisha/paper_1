{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bismillah.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNx1KIIF+5WTeCZ3fueUGhb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bone-Age-Maisha/paper_1/blob/main/SEnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras.utils"
      ],
      "metadata": {
        "id": "DmNk3QUS2y0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import os\n",
        "import sklearn.datasets \n",
        "import sklearn.model_selection \n",
        "import keras.preprocessing.image \n",
        "import keras.utils \n",
        "import matplotlib.pyplot as plt \n",
        "from keras.preprocessing.image import ImageDataGenerator \n",
        "from skimage import color \n",
        "from sklearn.metrics import accuracy_score\n",
        "import keras.callbacks \n",
        "import os \n",
        "import numpy as np \n",
        "import cv2\n"
      ],
      "metadata": {
        "id": "x1oBb3B-2RP_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJkqX3NN26Q8",
        "outputId": "e0472a2e-d7c8-4c5b-b42e-90c51d7e4981"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "metadata": {
        "id": "iG6QZsTO3PLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "jw3pOLXS3sIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_dir = '/content/drive/MyDrive/small_data/train'\n",
        "df = pd.read_csv('/content/drive/MyDrive/small_data/train_csv1.csv')"
      ],
      "metadata": {
        "id": "lCKTlkSF3uHX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#data processing ------------------------------"
      ],
      "metadata": {
        "id": "5qLzBl3O31PN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from six.moves import cPickle\n",
        "X_train = []\n",
        "y_age = []\n",
        "y_gender = []\n",
        "\n",
        "#df = pd.read_csv('/raid/chenchao/code/BoneAge/BoneAge/data/Training.csv')\n",
        "a = df.values\n",
        "m = a.shape[0]\n",
        "\n",
        "cnt=1\n",
        "path = train_dir\n",
        "k = 0\n",
        "print ('Loading data set...')\n",
        "k=1\n",
        "for i in os.listdir(path):\n",
        "  #print(i)\n",
        "  print(cnt)\n",
        "  cnt=cnt+1\n",
        "  if(len(i)>9):   #errror occuring  so to \n",
        "    continue\n",
        "  y_age.append(df.boneage[df.id == int(i[:-4])].tolist()[0])\n",
        "  a = df.male[df.id == int(i[:-4])].tolist()[0]\n",
        "  if a:\n",
        "    y_gender.append(1)\n",
        "  else:\n",
        "     y_gender.append(0)\n",
        "  img_path = path + \"/\"+i\n",
        "  img = cv2.imread(img_path)\n",
        "  #print(img.shape)\n",
        "  print (img_path)\n",
        "  img = cv2.imread(img_path)\n",
        "    #print (img_path)\n",
        "    #if(img is not None):\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  img = cv2.resize(img,(256,256))\n",
        "  x = np.asarray(img, dtype=np.uint8)\n",
        "  X_train.append(x)\n",
        "    \n",
        "print ('100% completed loading data')\n",
        "\n",
        "# Save data\n",
        "train_pkl = open('/content/drive/MyDrive/data.pkl','wb')\n",
        "cPickle.dump(X_train, train_pkl, protocol=cPickle.HIGHEST_PROTOCOL)\n",
        "train_pkl.close()\n",
        "\n",
        "train_age_pkl = open('/content/drive/MyDrive/data_age.pkl','wb')\n",
        "cPickle.dump(y_age, train_age_pkl, protocol=cPickle.HIGHEST_PROTOCOL)\n",
        "train_age_pkl.close()\n",
        "\n",
        "train_gender_pkl = open('/content/drive/MyDrive/data_gender.pkl','wb')\n",
        "cPickle.dump(y_gender, train_gender_pkl, protocol=cPickle.HIGHEST_PROTOCOL)\n",
        "train_gender_pkl.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "z89jQTDGBcQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def SaveImg(filename,filepath,heatmap):\n",
        "    img = cv2.imread(filepath)\n",
        "    heatmap = cv2.resize(heatmap,(img.shape[1],img.shape[0]))\n",
        "    AttentionImg =0.5* heatmap + img\n",
        "    cv2.imwrite('/content/heat'+filename,heatmap)\n",
        "    cv2.imwrite('/content/attention'+filename,AttentionImg)\n",
        "\n",
        "\n",
        "def load_image(path):\n",
        "    img = cv2.imread(path)\n",
        "    print(img.shape)\n",
        "    img = cv2.resize(img,(256,256))   ##my own edit\n",
        "    print(img.shape)\n",
        "    x = np.asarray(img, dtype=np.float32)\n",
        "   # img = image.load_img(path, target_size=(448, 448))\n",
        "   # print (img.shape)\n",
        "   # x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def softlabel(label,num_class):\n",
        "    softlabel=np.zeros((len(label),num_class))\n",
        "    ratio = 1.0/50\n",
        "    for i in range(len(label)):\n",
        "        for j in range(num_class):\n",
        "            softlabel[i,j]=1.0 - ratio*np.abs(j-label[i])\n",
        "    softlabel = np.maximum(softlabel,0)\n",
        "    return softlabel\n",
        "\n",
        "\n",
        "\n",
        "def GaussLabel(label,num_class):\n",
        "    sigma=15.0\n",
        "    GaussLabel = np.zeros((len(label),num_class))\n",
        "    x = np.array(range(num_class))+1\n",
        "    for k in range(len(label)):\n",
        "        GaussLabel[k,:]=np.exp(-(x-label[k])**2/(2.0*sigma**2))\n",
        "    return GaussLabel\n",
        "\n",
        "\n",
        "def TestMAE(model,test_data,test_label,test_gender):\n",
        "    test_gender = np.array(test_gender)\n",
        "    test_gender = np.expand_dims(test_gender,axis=1)\n",
        "    layer=K.function([model.layers[0].input,model.layers[3].input],[model.layers[-1].output])\n",
        "    predictions=layer([test_data,test_gender])\n",
        "    predictions = np.array(predictions)\n",
        "    predictions = np.squeeze(predictions,axis=0)\n",
        "    print (predictions.shape)\n",
        "    predict_label = np.argmax(predictions,axis=1)\n",
        "    test_label = np.argmax(test_label,axis=1)\n",
        "    print (predict_label)\n",
        "    print (test_label)\n",
        "    TestMAE = np.mean(np.abs(predict_label-test_label))\n",
        "    return TestMAE\n",
        "\n"
      ],
      "metadata": {
        "id": "q8bLrWYVz-yd"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.xception import Xception\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Flatten, Dense, Input, Reshape, Lambda\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "#from func_utils import *\n",
        "import os\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
        "#os.environ['OMP_NUM_THREADS']='6'\n",
        "batch_size = 32\n",
        "epochs = 30\n",
        "\n",
        "# Load data\n",
        "print('...loading training data')\n",
        "f = open('/content/drive/MyDrive/data.pkl', 'rb')\n",
        "x = pickle.load(f)\n",
        "f.close()\n",
        "\n",
        "f = open('/content/drive/MyDrive/data_age.pkl', 'rb')\n",
        "y = pickle.load(f)\n",
        "f.close()\n",
        "\n",
        "f = open('/content/drive/MyDrive/data_gender.pkl','rb')\n",
        "gender = pickle.load(f)\n",
        "f.close()\n",
        "\n",
        "\n",
        "x = np.asarray(x, dtype=np.float32)\n",
        "y = np.asarray(y)\n",
        "gender = np.asarray(gender)\n",
        "\n",
        "x /= 255.\n",
        "gender =2*( gender-0.5)\n",
        "x_final = []\n",
        "y_final = []\n",
        "gender_final = []\n",
        "\n",
        "# Shuffle images and split into train, validation and test sets\n",
        "#random_no = np.random.choice(x.shape[0], size=x.shape[0], replace=False)\n",
        "random_no = np.arange(x.shape[0])\n",
        "#print(random_no)\n",
        "np.random.seed(0)\n",
        "np.random.shuffle(random_no)\n",
        "for i in random_no:\n",
        "    x_final.append(x[i,:,:,:])\n",
        "    y_final.append(y[i])\n",
        "    gender_final.append(gender[i])\n",
        "\n",
        "x_final = np.asarray(x_final)\n",
        "y_final = np.asarray(y_final)\n",
        "gender_final = np.asarray(gender_final)\n",
        "print (y_final[:50])\n",
        "print (gender_final[:50])\n",
        "k = 10 # Decides split count\n",
        "x_test = x_final[:k,:,:,:]\n",
        "y_test = y_final[:k]\n",
        "gender_test = gender_final[:k]\n",
        "x_valid = x_final[k:2*k,:,:,:]\n",
        "y_valid = y_final[k:2*k]\n",
        "gender_valid = gender_final[k:2*k]\n",
        "x_train = x_final[2*k:,:,:,:]\n",
        "y_train = y_final[2*k:]\n",
        "gender_train = gender_final[2*k:]\n",
        "\n",
        "## \n",
        "#y_test = keras.utils.to_categorical(y_test,240)\n",
        "#y_train = keras.utils.to_categorical(y_train,240)\n",
        "#y_valid = keras.utils.to_categorical(y_valid,240)\n",
        "y_train = softlabel(y_train,240)\n",
        "y_valid = softlabel(y_valid,240)\n",
        "y_test = softlabel(y_test,240)\n",
        "print (y_train)\n",
        "\n",
        "\n",
        "print ('x_train shape:'+ str(x_train.shape))\n",
        "print ('y_train shape:'+ str(y_train.shape))\n",
        "print ('gender_train shape:'+ str(gender_train.shape))\n",
        "print ('x_valid shape:'+ str(x_valid.shape))\n",
        "print ('y_valid shape:'+ str(y_valid.shape))\n",
        "print ('gender_valid shape:' + str(gender_valid.shape))\n",
        "print ('x_test shape:'+ str(x_test.shape))\n",
        "print ('y_test shape:'+ str(y_test.shape))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIUzuP0y0Ikf",
        "outputId": "64363346-06bd-406b-eb0e-20d70c39919c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...loading training data\n",
            "[126  30 170  24  33 180 150  94  24  32  60 149  78  54 162 165 126  69\n",
            " 174  94  90 113 120  32 156  82  42  54 126 156  27 136 156  88 132  21\n",
            " 188 156 108 126  36 180  57  36 120 132 192 156 138 159]\n",
            "[ 1. -1.  1. -1. -1.  1.  1. -1. -1.  1.  1.  1.  1.  1. -1.  1. -1. -1.\n",
            "  1. -1.  1. -1.  1.  1.  1. -1.  1.  1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
            " -1. -1.  1.  1. -1. -1.  1.  1. -1. -1.  1.  1.  1. -1.]\n",
            "[[0.   0.   0.   ... 0.   0.   0.  ]\n",
            " [0.   0.   0.   ... 0.   0.   0.  ]\n",
            " [0.   0.   0.   ... 0.   0.   0.  ]\n",
            " ...\n",
            " [0.   0.02 0.04 ... 0.   0.   0.  ]\n",
            " [0.52 0.54 0.56 ... 0.   0.   0.  ]\n",
            " [0.34 0.36 0.38 ... 0.   0.   0.  ]]\n",
            "x_train shape:(51, 256, 256, 3)\n",
            "y_train shape:(51, 240)\n",
            "gender_train shape:(51,)\n",
            "x_valid shape:(10, 256, 256, 3)\n",
            "y_valid shape:(10, 240)\n",
            "gender_valid shape:(10,)\n",
            "x_test shape:(10, 256, 256, 3)\n",
            "y_test shape:(10, 240)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#model build--------------------"
      ],
      "metadata": {
        "id": "Ekzmkhgc35KP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = keras.layers.Input((256,256,3),name='input1')\n",
        "\n",
        "#inizio blocco 1\n",
        "x = keras.layers.Conv2D(filters=16, kernel_size=[1, 1], padding='same')(images)\n",
        "block = keras.layers.Conv2D(filters=16, kernel_size=[3, 3], padding=\"same\")(x)\n",
        "block = keras.layers.BatchNormalization()(block)\n",
        "block = keras.layers.Activation(\"relu\")(block)\n",
        "block = keras.layers.Conv2D(filters=16, kernel_size=[3, 3], padding=\"same\")(block)\n",
        "\n",
        "#inio Squeeze and Excitation 1\n",
        "sq = keras.layers.GlobalAveragePooling2D()(block)\n",
        "sq = keras.layers.Reshape((1,1,16))(sq)\n",
        "sq = keras.layers.Dense(units=16,activation=\"sigmoid\")(sq)\n",
        "block = keras.layers.multiply([block,sq])\n",
        "#fine Squeeze and Excitation 1\n",
        "\n",
        "net = keras.layers.add([x,block])\n",
        "net = keras.layers.BatchNormalization()(net)\n",
        "net = keras.layers.Activation(\"relu\")(net)\n",
        "net = keras.layers.MaxPooling2D(pool_size=(2, 2),name=\"block_1\")(net)\n",
        "\n",
        "\n",
        "\n",
        "#fine blocco 1\n",
        "#inizio blocco 2\n",
        "x = keras.layers.Conv2D(filters=32, kernel_size=[1, 1], padding='same')(net)\n",
        "block = keras.layers.Conv2D(filters=32, kernel_size=[3, 3], padding=\"same\")(x)\n",
        "block = keras.layers.BatchNormalization()(block)\n",
        "block = keras.layers.Activation(\"relu\")(block)\n",
        "block = keras.layers.Conv2D(filters=32, kernel_size=[3, 3], padding=\"same\")(block)\n",
        "\n",
        "#inio Squeeze and Excitation 2\n",
        "sq = keras.layers.GlobalAveragePooling2D()(block)\n",
        "sq = keras.layers.Reshape((1,1,32))(sq)\n",
        "sq = keras.layers.Dense(units=32,activation=\"sigmoid\")(sq)\n",
        "block = keras.layers.multiply([block,sq])\n",
        "#fine Squeeze and Excitation 2\n",
        "\n",
        "\n",
        "net = keras.layers.add([x,block])\n",
        "net = keras.layers.BatchNormalization()(net)\n",
        "net = keras.layers.Activation(\"relu\")(net)\n",
        "net = keras.layers.MaxPooling2D(pool_size=(2, 2),name=\"block_2\")(net)\n",
        "#fine blocco 2\n",
        "#inizio blocco 3\n",
        "x = keras.layers.Conv2D(filters=64, kernel_size=[1, 1], padding='same')(net)\n",
        "block = keras.layers.Conv2D(filters=64, kernel_size=[3, 3], padding=\"same\")(x)\n",
        "block = keras.layers.BatchNormalization()(block)\n",
        "block = keras.layers.Activation(\"relu\")(block)\n",
        "block = keras.layers.Conv2D(filters=64, kernel_size=[3, 3], padding=\"same\")(block)\n",
        "\n",
        "#inio Squeeze and Excitation 3\n",
        "sq = keras.layers.GlobalAveragePooling2D()(block)\n",
        "sq = keras.layers.Reshape((1,1,64))(sq)\n",
        "sq = keras.layers.Dense(units=64,activation=\"sigmoid\")(sq)\n",
        "block = keras.layers.multiply([block,sq])\n",
        "#fine Squeeze and Excitation 3\n",
        "\n",
        "net = keras.layers.add([x,block])\n",
        "net = keras.layers.Activation(\"relu\", name=\"block_3\")(net)\n",
        "\n",
        "\n",
        "\n",
        "net = keras.layers.BatchNormalization()(net)\n",
        "net = keras.layers.Dropout(0.25)(net)\n",
        "\n",
        "net = keras.layers.GlobalAveragePooling2D()(net)\n",
        "net = keras.layers.Dense(units=240,activation=\"softmax\")(net)\n",
        "\n",
        "model = keras.models.Model(inputs=images,outputs=net)\n",
        "\n",
        "\n",
        "model.summary()\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsbFjrWi39T1",
        "outputId": "bf2558ca-1092-4da1-c028-e81370114052"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input1 (InputLayer)            [(None, 256, 256, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 256, 256, 16  64          ['input1[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 256, 256, 16  2320        ['conv2d_18[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 256, 256, 16  64         ['conv2d_19[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 256, 256, 16  0           ['batch_normalization_12[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 256, 256, 16  2320        ['activation_10[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " global_average_pooling2d_8 (Gl  (None, 16)          0           ['conv2d_20[0][0]']              \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " reshape_6 (Reshape)            (None, 1, 1, 16)     0           ['global_average_pooling2d_8[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 1, 1, 16)     272         ['reshape_6[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 256, 256, 16  0           ['conv2d_20[0][0]',              \n",
            "                                )                                 'dense_7[0][0]']                \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 256, 256, 16  0           ['conv2d_18[0][0]',              \n",
            "                                )                                 'multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 256, 256, 16  64         ['add_6[0][0]']                  \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 256, 256, 16  0           ['batch_normalization_13[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block_1 (MaxPooling2D)         (None, 128, 128, 16  0           ['activation_11[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 128, 128, 32  544         ['block_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 128, 128, 32  9248        ['conv2d_21[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 128, 128, 32  128        ['conv2d_22[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 128, 128, 32  0           ['batch_normalization_14[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 128, 128, 32  9248        ['activation_12[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " global_average_pooling2d_9 (Gl  (None, 32)          0           ['conv2d_23[0][0]']              \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " reshape_7 (Reshape)            (None, 1, 1, 32)     0           ['global_average_pooling2d_9[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 1, 1, 32)     1056        ['reshape_7[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 128, 128, 32  0           ['conv2d_23[0][0]',              \n",
            "                                )                                 'dense_8[0][0]']                \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 128, 128, 32  0           ['conv2d_21[0][0]',              \n",
            "                                )                                 'multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 128, 128, 32  128        ['add_7[0][0]']                  \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 128, 128, 32  0           ['batch_normalization_15[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block_2 (MaxPooling2D)         (None, 64, 64, 32)   0           ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 64, 64, 64)   2112        ['block_2[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 64, 64, 64)   36928       ['conv2d_24[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 64, 64, 64)  256         ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 64, 64, 64)   36928       ['activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " global_average_pooling2d_10 (G  (None, 64)          0           ['conv2d_26[0][0]']              \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_8 (Reshape)            (None, 1, 1, 64)     0           ['global_average_pooling2d_10[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 1, 1, 64)     4160        ['reshape_8[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 64, 64, 64)   0           ['conv2d_26[0][0]',              \n",
            "                                                                  'dense_9[0][0]']                \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 64, 64, 64)   0           ['conv2d_24[0][0]',              \n",
            "                                                                  'multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " block_3 (Activation)           (None, 64, 64, 64)   0           ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 64, 64, 64)  256         ['block_3[0][0]']                \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 64, 64, 64)   0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " global_average_pooling2d_11 (G  (None, 64)          0           ['dropout_2[0][0]']              \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 240)          15600       ['global_average_pooling2d_11[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 121,696\n",
            "Trainable params: 121,248\n",
            "Non-trainable params: 448\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input1 (InputLayer)            [(None, 256, 256, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 256, 256, 16  64          ['input1[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 256, 256, 16  2320        ['conv2d_18[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 256, 256, 16  64         ['conv2d_19[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 256, 256, 16  0           ['batch_normalization_12[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 256, 256, 16  2320        ['activation_10[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " global_average_pooling2d_8 (Gl  (None, 16)          0           ['conv2d_20[0][0]']              \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " reshape_6 (Reshape)            (None, 1, 1, 16)     0           ['global_average_pooling2d_8[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 1, 1, 16)     272         ['reshape_6[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 256, 256, 16  0           ['conv2d_20[0][0]',              \n",
            "                                )                                 'dense_7[0][0]']                \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 256, 256, 16  0           ['conv2d_18[0][0]',              \n",
            "                                )                                 'multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 256, 256, 16  64         ['add_6[0][0]']                  \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 256, 256, 16  0           ['batch_normalization_13[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block_1 (MaxPooling2D)         (None, 128, 128, 16  0           ['activation_11[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 128, 128, 32  544         ['block_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 128, 128, 32  9248        ['conv2d_21[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 128, 128, 32  128        ['conv2d_22[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 128, 128, 32  0           ['batch_normalization_14[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 128, 128, 32  9248        ['activation_12[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " global_average_pooling2d_9 (Gl  (None, 32)          0           ['conv2d_23[0][0]']              \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " reshape_7 (Reshape)            (None, 1, 1, 32)     0           ['global_average_pooling2d_9[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 1, 1, 32)     1056        ['reshape_7[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 128, 128, 32  0           ['conv2d_23[0][0]',              \n",
            "                                )                                 'dense_8[0][0]']                \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 128, 128, 32  0           ['conv2d_21[0][0]',              \n",
            "                                )                                 'multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 128, 128, 32  128        ['add_7[0][0]']                  \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 128, 128, 32  0           ['batch_normalization_15[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block_2 (MaxPooling2D)         (None, 64, 64, 32)   0           ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 64, 64, 64)   2112        ['block_2[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 64, 64, 64)   36928       ['conv2d_24[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 64, 64, 64)  256         ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 64, 64, 64)   36928       ['activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " global_average_pooling2d_10 (G  (None, 64)          0           ['conv2d_26[0][0]']              \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_8 (Reshape)            (None, 1, 1, 64)     0           ['global_average_pooling2d_10[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 1, 1, 64)     4160        ['reshape_8[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 64, 64, 64)   0           ['conv2d_26[0][0]',              \n",
            "                                                                  'dense_9[0][0]']                \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 64, 64, 64)   0           ['conv2d_24[0][0]',              \n",
            "                                                                  'multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " block_3 (Activation)           (None, 64, 64, 64)   0           ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 64, 64, 64)  256         ['block_3[0][0]']                \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 64, 64, 64)   0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " global_average_pooling2d_11 (G  (None, 64)          0           ['dropout_2[0][0]']              \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 240)          15600       ['global_average_pooling2d_11[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 121,696\n",
            "Trainable params: 121,248\n",
            "Non-trainable params: 448\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Adam=tf.keras.optimizers.Adam(lr=0.0003,beta_1=0.9,beta_2=0.999)\n",
        "model.compile(loss='mean_absolute_error',optimizer=Adam,  metrics=['MAE'])\n",
        "checkpointer = keras.callbacks.ModelCheckpoint(filepath = '/content/drive/MyDrive/se.hdf5', verbose = 1, save_best_only = True)\n",
        "earlystopper = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto', baseline=None, restore_best_weights=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPbwHFoN4qbl",
        "outputId": "453f6784-ce25-4682-8fa2-16b7b9937f38"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(x_train, y_train, batch_size=26, epochs=50,validation_data=(x_valid, y_valid), callbacks = [checkpointer,earlystopper], shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0DG5WI67KJH",
        "outputId": "822e1609-286a-4dba-cbd9-40e0bf47510d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f5910040b00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f5910040b00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f5910040b00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2027 - MAE: 0.2027WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f58aa707830> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f58aa707830> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f58aa707830> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.20906, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 2s 710ms/step - loss: 0.2027 - MAE: 0.2027 - val_loss: 0.2091 - val_MAE: 0.2091\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2027 - MAE: 0.2027\n",
            "Epoch 2: val_loss did not improve from 0.20906\n",
            "2/2 [==============================] - 0s 190ms/step - loss: 0.2027 - MAE: 0.2027 - val_loss: 0.2091 - val_MAE: 0.2091\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2027 - MAE: 0.2027\n",
            "Epoch 3: val_loss did not improve from 0.20906\n",
            "2/2 [==============================] - 0s 192ms/step - loss: 0.2027 - MAE: 0.2027 - val_loss: 0.2091 - val_MAE: 0.2091\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2026 - MAE: 0.2026\n",
            "Epoch 4: val_loss improved from 0.20906 to 0.20906, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 0s 344ms/step - loss: 0.2026 - MAE: 0.2026 - val_loss: 0.2091 - val_MAE: 0.2091\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2026 - MAE: 0.2026\n",
            "Epoch 5: val_loss improved from 0.20906 to 0.20906, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 0s 338ms/step - loss: 0.2026 - MAE: 0.2026 - val_loss: 0.2091 - val_MAE: 0.2091\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2025 - MAE: 0.2025\n",
            "Epoch 6: val_loss improved from 0.20906 to 0.20906, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 0s 346ms/step - loss: 0.2025 - MAE: 0.2025 - val_loss: 0.2091 - val_MAE: 0.2091\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2025 - MAE: 0.2025\n",
            "Epoch 7: val_loss improved from 0.20906 to 0.20906, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 1s 348ms/step - loss: 0.2025 - MAE: 0.2025 - val_loss: 0.2091 - val_MAE: 0.2091\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2025 - MAE: 0.2025\n",
            "Epoch 8: val_loss improved from 0.20906 to 0.20906, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 1s 350ms/step - loss: 0.2025 - MAE: 0.2025 - val_loss: 0.2091 - val_MAE: 0.2091\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2024 - MAE: 0.2024\n",
            "Epoch 9: val_loss improved from 0.20906 to 0.20906, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 0s 339ms/step - loss: 0.2024 - MAE: 0.2024 - val_loss: 0.2091 - val_MAE: 0.2091\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2024 - MAE: 0.2024\n",
            "Epoch 10: val_loss improved from 0.20906 to 0.20906, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 0s 338ms/step - loss: 0.2024 - MAE: 0.2024 - val_loss: 0.2091 - val_MAE: 0.2091\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2024 - MAE: 0.2024\n",
            "Epoch 11: val_loss improved from 0.20906 to 0.20906, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 1s 357ms/step - loss: 0.2024 - MAE: 0.2024 - val_loss: 0.2091 - val_MAE: 0.2091\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2023 - MAE: 0.2023\n",
            "Epoch 12: val_loss improved from 0.20906 to 0.20906, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 1s 347ms/step - loss: 0.2023 - MAE: 0.2023 - val_loss: 0.2091 - val_MAE: 0.2091\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2023 - MAE: 0.2023\n",
            "Epoch 13: val_loss improved from 0.20906 to 0.20905, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 1s 345ms/step - loss: 0.2023 - MAE: 0.2023 - val_loss: 0.2091 - val_MAE: 0.2091\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2024 - MAE: 0.2024\n",
            "Epoch 14: val_loss improved from 0.20905 to 0.20905, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 0s 342ms/step - loss: 0.2024 - MAE: 0.2024 - val_loss: 0.2091 - val_MAE: 0.2091\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2022 - MAE: 0.2022\n",
            "Epoch 15: val_loss improved from 0.20905 to 0.20905, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 1s 345ms/step - loss: 0.2022 - MAE: 0.2022 - val_loss: 0.2091 - val_MAE: 0.2091\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2023 - MAE: 0.2023\n",
            "Epoch 16: val_loss improved from 0.20905 to 0.20905, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 0s 344ms/step - loss: 0.2023 - MAE: 0.2023 - val_loss: 0.2090 - val_MAE: 0.2090\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2023 - MAE: 0.2023\n",
            "Epoch 17: val_loss improved from 0.20905 to 0.20905, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 0s 343ms/step - loss: 0.2023 - MAE: 0.2023 - val_loss: 0.2090 - val_MAE: 0.2090\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2022 - MAE: 0.2022\n",
            "Epoch 18: val_loss improved from 0.20905 to 0.20905, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 0s 339ms/step - loss: 0.2022 - MAE: 0.2022 - val_loss: 0.2090 - val_MAE: 0.2090\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2020 - MAE: 0.2020\n",
            "Epoch 19: val_loss improved from 0.20905 to 0.20904, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 1s 352ms/step - loss: 0.2020 - MAE: 0.2020 - val_loss: 0.2090 - val_MAE: 0.2090\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2021 - MAE: 0.2021\n",
            "Epoch 20: val_loss improved from 0.20904 to 0.20904, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 1s 348ms/step - loss: 0.2021 - MAE: 0.2021 - val_loss: 0.2090 - val_MAE: 0.2090\n",
            "Epoch 21/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2020 - MAE: 0.2020\n",
            "Epoch 21: val_loss improved from 0.20904 to 0.20904, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 1s 403ms/step - loss: 0.2020 - MAE: 0.2020 - val_loss: 0.2090 - val_MAE: 0.2090\n",
            "Epoch 22/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2020 - MAE: 0.2020\n",
            "Epoch 22: val_loss improved from 0.20904 to 0.20903, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 1s 347ms/step - loss: 0.2020 - MAE: 0.2020 - val_loss: 0.2090 - val_MAE: 0.2090\n",
            "Epoch 23/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2020 - MAE: 0.2020\n",
            "Epoch 23: val_loss improved from 0.20903 to 0.20903, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 1s 357ms/step - loss: 0.2020 - MAE: 0.2020 - val_loss: 0.2090 - val_MAE: 0.2090\n",
            "Epoch 24/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2019 - MAE: 0.2019\n",
            "Epoch 24: val_loss improved from 0.20903 to 0.20903, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 1s 352ms/step - loss: 0.2019 - MAE: 0.2019 - val_loss: 0.2090 - val_MAE: 0.2090\n",
            "Epoch 25/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2019 - MAE: 0.2019\n",
            "Epoch 25: val_loss improved from 0.20903 to 0.20902, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 1s 353ms/step - loss: 0.2019 - MAE: 0.2019 - val_loss: 0.2090 - val_MAE: 0.2090\n",
            "Epoch 26/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2019 - MAE: 0.2019\n",
            "Epoch 26: val_loss improved from 0.20902 to 0.20902, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 1s 352ms/step - loss: 0.2019 - MAE: 0.2019 - val_loss: 0.2090 - val_MAE: 0.2090\n",
            "Epoch 27/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2020 - MAE: 0.2020\n",
            "Epoch 27: val_loss improved from 0.20902 to 0.20902, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 1s 355ms/step - loss: 0.2020 - MAE: 0.2020 - val_loss: 0.2090 - val_MAE: 0.2090\n",
            "Epoch 28/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2018 - MAE: 0.2018\n",
            "Epoch 28: val_loss improved from 0.20902 to 0.20901, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 1s 353ms/step - loss: 0.2018 - MAE: 0.2018 - val_loss: 0.2090 - val_MAE: 0.2090\n",
            "Epoch 29/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2018 - MAE: 0.2018\n",
            "Epoch 29: val_loss improved from 0.20901 to 0.20901, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 1s 364ms/step - loss: 0.2018 - MAE: 0.2018 - val_loss: 0.2090 - val_MAE: 0.2090\n",
            "Epoch 30/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2019 - MAE: 0.2019\n",
            "Epoch 30: val_loss improved from 0.20901 to 0.20901, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 1s 359ms/step - loss: 0.2019 - MAE: 0.2019 - val_loss: 0.2090 - val_MAE: 0.2090\n",
            "Epoch 31/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2017 - MAE: 0.2017\n",
            "Epoch 31: val_loss improved from 0.20901 to 0.20901, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 1s 375ms/step - loss: 0.2017 - MAE: 0.2017 - val_loss: 0.2090 - val_MAE: 0.2090\n",
            "Epoch 32/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2016 - MAE: 0.2016\n",
            "Epoch 32: val_loss improved from 0.20901 to 0.20901, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 1s 352ms/step - loss: 0.2016 - MAE: 0.2016 - val_loss: 0.2090 - val_MAE: 0.2090\n",
            "Epoch 33/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2017 - MAE: 0.2017\n",
            "Epoch 33: val_loss improved from 0.20901 to 0.20900, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 1s 348ms/step - loss: 0.2017 - MAE: 0.2017 - val_loss: 0.2090 - val_MAE: 0.2090\n",
            "Epoch 34/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2023 - MAE: 0.2023\n",
            "Epoch 34: val_loss did not improve from 0.20900\n",
            "2/2 [==============================] - 0s 197ms/step - loss: 0.2023 - MAE: 0.2023 - val_loss: 0.2090 - val_MAE: 0.2090\n",
            "Epoch 35/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2017 - MAE: 0.2017\n",
            "Epoch 35: val_loss did not improve from 0.20900\n",
            "2/2 [==============================] - 0s 193ms/step - loss: 0.2017 - MAE: 0.2017 - val_loss: 0.2090 - val_MAE: 0.2090\n",
            "Epoch 36/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2019 - MAE: 0.2019\n",
            "Epoch 36: val_loss did not improve from 0.20900\n",
            "2/2 [==============================] - 0s 190ms/step - loss: 0.2019 - MAE: 0.2019 - val_loss: 0.2090 - val_MAE: 0.2090\n",
            "Epoch 37/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2016 - MAE: 0.2016\n",
            "Epoch 37: val_loss did not improve from 0.20900\n",
            "2/2 [==============================] - 0s 195ms/step - loss: 0.2016 - MAE: 0.2016 - val_loss: 0.2090 - val_MAE: 0.2090\n",
            "Epoch 38/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2017 - MAE: 0.2017\n",
            "Epoch 38: val_loss improved from 0.20900 to 0.20900, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 1s 354ms/step - loss: 0.2017 - MAE: 0.2017 - val_loss: 0.2090 - val_MAE: 0.2090\n",
            "Epoch 39/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2015 - MAE: 0.2015\n",
            "Epoch 39: val_loss improved from 0.20900 to 0.20899, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 1s 349ms/step - loss: 0.2015 - MAE: 0.2015 - val_loss: 0.2090 - val_MAE: 0.2090\n",
            "Epoch 40/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2014 - MAE: 0.2014\n",
            "Epoch 40: val_loss improved from 0.20899 to 0.20898, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 1s 346ms/step - loss: 0.2014 - MAE: 0.2014 - val_loss: 0.2090 - val_MAE: 0.2090\n",
            "Epoch 41/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2013 - MAE: 0.2013\n",
            "Epoch 41: val_loss improved from 0.20898 to 0.20898, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 1s 353ms/step - loss: 0.2013 - MAE: 0.2013 - val_loss: 0.2090 - val_MAE: 0.2090\n",
            "Epoch 42/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2015 - MAE: 0.2015\n",
            "Epoch 42: val_loss improved from 0.20898 to 0.20897, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 1s 367ms/step - loss: 0.2015 - MAE: 0.2015 - val_loss: 0.2090 - val_MAE: 0.2090\n",
            "Epoch 43/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2012 - MAE: 0.2012\n",
            "Epoch 43: val_loss improved from 0.20897 to 0.20896, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 1s 356ms/step - loss: 0.2012 - MAE: 0.2012 - val_loss: 0.2090 - val_MAE: 0.2090\n",
            "Epoch 44/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2013 - MAE: 0.2013\n",
            "Epoch 44: val_loss improved from 0.20896 to 0.20894, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 1s 350ms/step - loss: 0.2013 - MAE: 0.2013 - val_loss: 0.2089 - val_MAE: 0.2089\n",
            "Epoch 45/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2011 - MAE: 0.2011\n",
            "Epoch 45: val_loss improved from 0.20894 to 0.20893, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 1s 347ms/step - loss: 0.2011 - MAE: 0.2011 - val_loss: 0.2089 - val_MAE: 0.2089\n",
            "Epoch 46/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2012 - MAE: 0.2012\n",
            "Epoch 46: val_loss improved from 0.20893 to 0.20892, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 1s 354ms/step - loss: 0.2012 - MAE: 0.2012 - val_loss: 0.2089 - val_MAE: 0.2089\n",
            "Epoch 47/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2011 - MAE: 0.2011\n",
            "Epoch 47: val_loss did not improve from 0.20892\n",
            "2/2 [==============================] - 0s 196ms/step - loss: 0.2011 - MAE: 0.2011 - val_loss: 0.2089 - val_MAE: 0.2089\n",
            "Epoch 48/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2013 - MAE: 0.2013\n",
            "Epoch 48: val_loss did not improve from 0.20892\n",
            "2/2 [==============================] - 0s 195ms/step - loss: 0.2013 - MAE: 0.2013 - val_loss: 0.2089 - val_MAE: 0.2089\n",
            "Epoch 49/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2011 - MAE: 0.2011\n",
            "Epoch 49: val_loss improved from 0.20892 to 0.20892, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 1s 348ms/step - loss: 0.2011 - MAE: 0.2011 - val_loss: 0.2089 - val_MAE: 0.2089\n",
            "Epoch 50/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2012 - MAE: 0.2012\n",
            "Epoch 50: val_loss improved from 0.20892 to 0.20891, saving model to /content/drive/MyDrive/se.hdf5\n",
            "2/2 [==============================] - 1s 349ms/step - loss: 0.2012 - MAE: 0.2012 - val_loss: 0.2089 - val_MAE: 0.2089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('/content/drive/MyDrive/se.hdf5')"
      ],
      "metadata": {
        "id": "IWIggNL376Qv"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['MAE'])\n",
        "plt.plot(history.history['val_MAE'])\n",
        "plt.title('Model MAE')\n",
        "plt.ylabel('MAE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "0UH1Ekro8zvP",
        "outputId": "ad3a9a2a-592f-4131-f9bf-f971ce15ca44"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = model.predict(x_test)\n",
        "//accuracy_score(np.argmax(y_test_pred,axis=1), np.argmax(y_test,axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeDTKbrE931P",
        "outputId": "660c6fbe-932b-409f-bc19-db6154a0c138"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f5894164ef0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f5894164ef0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f5894164ef0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "print('Test loss:', score[0])\n",
        "print('Test MAE:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y3UN0Lh_HYf",
        "outputId": "5c880423-efa8-4ea9-c693-fa876547104c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 56ms/step - loss: 0.2001 - MAE: 0.2001\n",
            "Test loss: 0.20012840628623962\n",
            "Test MAE: 0.20012840628623962\n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/C4rvKy5IsB5Mj807k6w6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bone-Age-Maisha/paper_1/blob/main/sq_ex_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ix94RLqxik1r",
        "outputId": "fb263739-f0e5-479b-f59c-254a19eb1b7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "DYoJEf0Riuze"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_dir = '/content/drive/MyDrive/small_data/train'\n",
        "df = pd.read_csv('/content/drive/MyDrive/small_data/train_csv1.csv')"
      ],
      "metadata": {
        "id": "sy_WvLoDjHgr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
        "tf.config.experimental.set_memory_growth(gpus[0], True)"
      ],
      "metadata": {
        "id": "XG9iLrSMjR9j"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "y_age = []\n",
        "y_gender = []\n",
        "\n",
        "#df = pd.read_csv('/raid/chenchao/code/BoneAge/BoneAge/data/Training.csv')\n",
        "a = df.values\n",
        "m = a.shape[0]\n",
        "\n",
        "path = train_dir\n",
        "k = 0\n",
        "print ('Loading data set...')\n",
        "k=1\n",
        "for i in os.listdir(path):\n",
        "  #print(i)\n",
        "  if(len(i)>9):   #errror occuring  so to \n",
        "    continue\n",
        "  y_age.append(df.boneage[df.id == int(i[:-4])].tolist()[0])\n",
        "  a = df.male[df.id == int(i[:-4])].tolist()[0]\n",
        "  if a:\n",
        "    y_gender.append(1)\n",
        "  else:\n",
        "     y_gender.append(0)\n",
        "  img_path = path + \"/\"+i\n",
        "  img = cv2.imread(img_path)\n",
        "  #print(img.shape)\n",
        "  #print (img_path)\n",
        "  img = cv2.imread(img_path)\n",
        "    #print (img_path)\n",
        "    #if(img is not None):\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  img = cv2.resize(img,(300,300))\n",
        "  x = np.asarray(img, dtype=np.uint8)\n",
        "  X_train.append(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpVv9yFsjW67",
        "outputId": "e8f9e3c0-ea62-4124-8f85-bc8b0c58e5cf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data set...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softlabel(label,num_class):\n",
        "    softlabel=np.zeros((len(label),num_class))\n",
        "    ratio = 1.0/50\n",
        "    for i in range(len(label)):\n",
        "        for j in range(num_class):\n",
        "            softlabel[i,j]=1.0 - ratio*np.abs(j-label[i])\n",
        "    softlabel = np.maximum(softlabel,0)\n",
        "    return softlabel"
      ],
      "metadata": {
        "id": "6aUl5zLujjIc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.asarray(y_age)\n",
        "gender = np.asarray(y_gender)\n",
        "x=np.asarray(X_train, dtype=np.float32)\n",
        "x/255\n",
        "gender =2*( gender-0.5)\n",
        "x_final = []\n",
        "y_final = []\n",
        "gender_final = []\n",
        "\n",
        "# Shuffle images and split into train, validation and test sets\n",
        "#random_no = np.random.choice(x.shape[0], size=x.shape[0], replace=False)\n",
        "random_no = np.arange(x.shape[0])\n",
        "#print(random_no)\n",
        "np.random.seed(0)\n",
        "np.random.shuffle(random_no)\n",
        "for i in random_no:\n",
        "    x_final.append(x[i,:,:,:])\n",
        "    y_final.append(y[i])\n",
        "    gender_final.append(gender[i])\n",
        "\n",
        "x_final = np.asarray(x_final)\n",
        "y_final = np.asarray(y_final)\n",
        "gender_final = np.asarray(gender_final)\n",
        "print (y_final[:50])\n",
        "print (gender_final[:50])\n",
        "k = 10 # Decides split count\n",
        "x_test = x_final[:k,:,:,:]\n",
        "y_test = y_final[:k]\n",
        "gender_test = gender_final[:k]\n",
        "x_valid = x_final[k:2*k,:,:,:]\n",
        "y_valid = y_final[k:2*k]\n",
        "gender_valid = gender_final[k:2*k]\n",
        "x_train = x_final[2*k:,:,:,:]\n",
        "y_train = y_final[2*k:]\n",
        "gender_train = gender_final[2*k:]\n",
        "\n",
        "## \n",
        "#y_test = keras.utils.to_categorical(y_test,240)\n",
        "#y_train = keras.utils.to_categorical(y_train,240)\n",
        "#y_valid = keras.utils.to_categorical(y_valid,240)\n",
        "y_train = softlabel(y_train,240)\n",
        "y_valid = softlabel(y_valid,240)\n",
        "y_test = softlabel(y_test,240)\n",
        "print (y_train)\n",
        "\n",
        "\n",
        "print ('x_train shape:'+ str(x_train.shape))\n",
        "print ('y_train shape:'+ str(y_train.shape))\n",
        "print ('gender_train shape:'+ str(gender_train.shape))\n",
        "print ('x_valid shape:'+ str(x_valid.shape))\n",
        "print ('y_valid shape:'+ str(y_valid.shape))\n",
        "print ('gender_valid shape:' + str(gender_valid.shape))\n",
        "print ('x_test shape:'+ str(x_test.shape))\n",
        "print ('y_test shape:'+ str(y_test.shape))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbTT0EIVjpB8",
        "outputId": "8f71c3da-dba8-46c0-ccb7-c6b430166dba"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 30 149 113 132  33 136 150  94  24  32  60 126  88 174  78  42  21  21\n",
            "  54  82 192  24  94  32 156 120 165  33 138 156  27 108  42 162  57 126\n",
            "   4 156 180  88  36 180 132 156 120  60  90 138 138 120]\n",
            "[-1.  1. -1. -1. -1. -1.  1. -1. -1.  1.  1.  1. -1.  1.  1.  1. -1.  1.\n",
            "  1. -1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1. -1.  1. -1.\n",
            " -1. -1.  1.  1. -1. -1. -1.  1. -1. -1.  1.  1.  1. -1.]\n",
            "[[0.   0.   0.   ... 0.1  0.08 0.06]\n",
            " [0.52 0.54 0.56 ... 0.   0.   0.  ]\n",
            " [0.   0.   0.   ... 0.   0.   0.  ]\n",
            " ...\n",
            " [0.   0.02 0.04 ... 0.   0.   0.  ]\n",
            " [0.   0.   0.   ... 0.   0.   0.  ]\n",
            " [0.   0.   0.   ... 0.   0.   0.  ]]\n",
            "x_train shape:(51, 300, 300, 3)\n",
            "y_train shape:(51, 240)\n",
            "gender_train shape:(51,)\n",
            "x_valid shape:(10, 300, 300, 3)\n",
            "y_valid shape:(10, 240)\n",
            "gender_valid shape:(10,)\n",
            "x_test shape:(10, 300, 300, 3)\n",
            "y_test shape:(10, 240)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install visualization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8znEh88ajrd8",
        "outputId": "59f90ebd-47be-40cd-e9ca-e9428f4fa532"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting visualization\n",
            "  Downloading visualization-1.0.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from visualization) (1.21.6)\n",
            "Collecting pyrender\n",
            "  Downloading pyrender-0.1.45-py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 36.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from visualization) (2.9.0)\n",
            "Collecting trimesh[easy]\n",
            "  Downloading trimesh-3.16.4-py3-none-any.whl (663 kB)\n",
            "\u001b[K     |████████████████████████████████| 663 kB 68.4 MB/s \n",
            "\u001b[?25hCollecting autolab-core\n",
            "  Downloading autolab_core-1.1.1-py3-none-any.whl (116 kB)\n",
            "\u001b[K     |████████████████████████████████| 116 kB 65.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from visualization) (3.2.2)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 72.4 MB/s \n",
            "\u001b[?25hCollecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from autolab-core->visualization) (7.1.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from autolab-core->visualization) (0.18.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from autolab-core->visualization) (1.0.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from autolab-core->visualization) (1.2.0)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from autolab-core->visualization) (4.6.0.66)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from autolab-core->visualization) (1.7.3)\n",
            "Collecting ruamel.yaml\n",
            "  Downloading ruamel.yaml-0.17.21-py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 52.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->visualization) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->visualization) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->visualization) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->visualization) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->visualization) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->visualization) (1.15.0)\n",
            "Requirement already satisfied: dill>=0.3.6 in /usr/local/lib/python3.7/dist-packages (from multiprocess->autolab-core->visualization) (0.3.6)\n",
            "Collecting freetype-py\n",
            "  Downloading freetype_py-2.3.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (978 kB)\n",
            "\u001b[K     |████████████████████████████████| 978 kB 65.7 MB/s \n",
            "\u001b[?25hCollecting pyglet>=1.4.10\n",
            "  Downloading pyglet-2.0.0-py3-none-any.whl (966 kB)\n",
            "\u001b[K     |████████████████████████████████| 966 kB 32.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from pyrender->visualization) (2.6.3)\n",
            "Collecting PyOpenGL==3.1.0\n",
            "  Downloading PyOpenGL-3.1.0.zip (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 54.3 MB/s \n",
            "\u001b[?25hCollecting ruamel.yaml.clib>=0.2.6\n",
            "  Downloading ruamel.yaml.clib-0.2.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (500 kB)\n",
            "\u001b[K     |████████████████████████████████| 500 kB 65.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->autolab-core->visualization) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->autolab-core->visualization) (1.3.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->autolab-core->visualization) (3.1.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from trimesh[easy]->visualization) (1.0.4)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from trimesh[easy]->visualization) (3.0.4)\n",
            "Collecting pyglet>=1.4.10\n",
            "  Downloading pyglet-1.5.27-py3-none-any.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 57.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from trimesh[easy]->visualization) (2.23.0)\n",
            "Collecting pycollada\n",
            "  Downloading pycollada-0.7.2.tar.gz (107 kB)\n",
            "\u001b[K     |████████████████████████████████| 107 kB 71.9 MB/s \n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 68.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from trimesh[easy]->visualization) (1.7.1)\n",
            "Collecting mapbox-earcut\n",
            "  Downloading mapbox_earcut-1.0.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from trimesh[easy]->visualization) (4.3.3)\n",
            "Collecting rtree\n",
            "  Downloading Rtree-1.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 63.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from trimesh[easy]->visualization) (4.9.1)\n",
            "Collecting svg.path\n",
            "  Downloading svg.path-6.2-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from trimesh[easy]->visualization) (57.4.0)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.7/dist-packages (from trimesh[easy]->visualization) (1.8.5.post1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema->trimesh[easy]->visualization) (4.13.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->trimesh[easy]->visualization) (22.1.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->trimesh[easy]->visualization) (5.10.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->trimesh[easy]->visualization) (0.19.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema->trimesh[easy]->visualization) (3.10.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->trimesh[easy]->visualization) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->trimesh[easy]->visualization) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->trimesh[easy]->visualization) (2022.9.24)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->trimesh[easy]->visualization) (1.2.1)\n",
            "Building wheels for collected packages: PyOpenGL, pycollada\n",
            "  Building wheel for PyOpenGL (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyOpenGL: filename=PyOpenGL-3.1.0-py3-none-any.whl size=1745210 sha256=43087385fab0c05d0ba694ae1c00cef91ff81599cbdb537e484a329bdbaf4d26\n",
            "  Stored in directory: /root/.cache/pip/wheels/c6/83/cb/af51a0c06c33d08537b941bbfc87469e8a3c68d05f77a6a212\n",
            "  Building wheel for pycollada (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycollada: filename=pycollada-0.7.2-py3-none-any.whl size=127026 sha256=3dc92cfee01875d1c2b2ce29712f96eaa29607765b2beaae639a40cc31aca24c\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/0b/be/6cad4a774484615180dc30a68ff3635fbc36cccf489bcd6543\n",
            "Successfully built PyOpenGL pycollada\n",
            "Installing collected packages: ruamel.yaml.clib, xxhash, trimesh, svg.path, setproctitle, ruamel.yaml, rtree, PyOpenGL, pyglet, pycollada, multiprocess, mapbox-earcut, freetype-py, colorlog, pyrender, autolab-core, visualization\n",
            "  Attempting uninstall: PyOpenGL\n",
            "    Found existing installation: PyOpenGL 3.1.6\n",
            "    Uninstalling PyOpenGL-3.1.6:\n",
            "      Successfully uninstalled PyOpenGL-3.1.6\n",
            "Successfully installed PyOpenGL-3.1.0 autolab-core-1.1.1 colorlog-6.7.0 freetype-py-2.3.0 mapbox-earcut-1.0.0 multiprocess-0.70.14 pycollada-0.7.2 pyglet-1.5.27 pyrender-0.1.45 rtree-1.0.1 ruamel.yaml-0.17.21 ruamel.yaml.clib-0.2.7 setproctitle-1.3.2 svg.path-6.2 trimesh-3.16.4 visualization-1.0.0 xxhash-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.xception import Xception\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Flatten, Dense, Input, Reshape, Lambda\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "#from func_utils import *\n",
        "import os"
      ],
      "metadata": {
        "id": "9poqeFGdkO8W"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = Input(shape=(300,300,3),name='input1')\n",
        "\n",
        "#inizio blocco 1\n",
        "x = keras.layers.Conv2D(filters=16, kernel_size=[1, 1], padding='same')(input)\n",
        "block = keras.layers.Conv2D(filters=16, kernel_size=[3, 3], padding=\"same\")(x)\n",
        "block = keras.layers.BatchNormalization()(block)\n",
        "block = keras.layers.Activation(\"relu\")(block)\n",
        "block = keras.layers.Conv2D(filters=16, kernel_size=[3, 3], padding=\"same\")(block)\n",
        "\n",
        "#inio Squeeze and Excitation 1\n",
        "sq = keras.layers.GlobalAveragePooling2D()(block)\n",
        "sq = keras.layers.Reshape((1,1,16))(sq)\n",
        "sq = keras.layers.Dense(units=16,activation=\"sigmoid\")(sq)\n",
        "block = keras.layers.multiply([block,sq])\n",
        "#fine Squeeze and Excitation 1\n",
        "\n",
        "net = keras.layers.add([x,block])\n",
        "net = keras.layers.BatchNormalization()(net)\n",
        "net = keras.layers.Activation(\"relu\")(net)\n",
        "net = keras.layers.MaxPooling2D(pool_size=(2, 2),name=\"block_1\")(net)\n",
        "\n",
        "\n",
        "\n",
        "#fine blocco 1\n",
        "#inizio blocco 2\n",
        "x = keras.layers.Conv2D(filters=32, kernel_size=[1, 1], padding='same')(net)\n",
        "block = keras.layers.Conv2D(filters=32, kernel_size=[3, 3], padding=\"same\")(x)\n",
        "block = keras.layers.BatchNormalization()(block)\n",
        "block = keras.layers.Activation(\"relu\")(block)\n",
        "block = keras.layers.Conv2D(filters=32, kernel_size=[3, 3], padding=\"same\")(block)\n",
        "\n",
        "#inio Squeeze and Excitation 2\n",
        "sq = keras.layers.GlobalAveragePooling2D()(block)\n",
        "sq = keras.layers.Reshape((1,1,32))(sq)\n",
        "sq = keras.layers.Dense(units=32,activation=\"sigmoid\")(sq)\n",
        "block = keras.layers.multiply([block,sq])\n",
        "#fine Squeeze and Excitation 2\n",
        "\n",
        "\n",
        "net = keras.layers.add([x,block])\n",
        "net = keras.layers.BatchNormalization()(net)\n",
        "net = keras.layers.Activation(\"relu\")(net)\n",
        "net = keras.layers.MaxPooling2D(pool_size=(2, 2),name=\"block_2\")(net)\n",
        "#fine blocco 2\n",
        "#inizio blocco 3\n",
        "x = keras.layers.Conv2D(filters=64, kernel_size=[1, 1], padding='same')(net)\n",
        "block = keras.layers.Conv2D(filters=64, kernel_size=[3, 3], padding=\"same\")(x)\n",
        "block = keras.layers.BatchNormalization()(block)\n",
        "block = keras.layers.Activation(\"relu\")(block)\n",
        "block = keras.layers.Conv2D(filters=64, kernel_size=[3, 3], padding=\"same\")(block)\n",
        "\n",
        "#inio Squeeze and Excitation 3\n",
        "sq = keras.layers.GlobalAveragePooling2D()(block)\n",
        "sq = keras.layers.Reshape((1,1,64))(sq)\n",
        "sq = keras.layers.Dense(units=64,activation=\"sigmoid\")(sq)\n",
        "block = keras.layers.multiply([block,sq])\n",
        "#fine Squeeze and Excitation 3\n",
        "\n",
        "net = keras.layers.add([x,block])\n",
        "net = keras.layers.Activation(\"relu\", name=\"block_3\")(net)\n",
        "\n",
        "\n",
        "\n",
        "net = keras.layers.BatchNormalization()(net)\n",
        "net = keras.layers.Dropout(0.25)(net)\n",
        "\n",
        "net = keras.layers.GlobalAveragePooling2D()(net)\n",
        "input_gender = Input(shape=(1,),dtype='float32',name='input2')\n",
        "gender_embedding=Dense(16)(input_gender)\n",
        "x=Flatten()(net)\n",
        "f = keras.layers.Concatenate(axis=1)([net,gender_embedding])\n",
        "print (K.int_shape(f)) \n",
        "#x = Dense(256, activation='relu')(x)\n",
        "predictions = Dense(240)(f)\n",
        "\n",
        "model = keras.models.Model(inputs=[input,input_gender], outputs=predictions)\n",
        "\n",
        "model.summary()\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svvqpClwkfiX",
        "outputId": "79699b13-c14b-4ff6-832b-202fc311b638"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 80)\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input1 (InputLayer)            [(None, 300, 300, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 300, 300, 16  64          ['input1[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 300, 300, 16  2320        ['conv2d_36[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 300, 300, 16  64         ['conv2d_37[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 300, 300, 16  0           ['batch_normalization_24[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 300, 300, 16  2320        ['activation_20[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " global_average_pooling2d_16 (G  (None, 16)          0           ['conv2d_38[0][0]']              \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_12 (Reshape)           (None, 1, 1, 16)     0           ['global_average_pooling2d_16[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " dense_19 (Dense)               (None, 1, 1, 16)     272         ['reshape_12[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 300, 300, 16  0           ['conv2d_38[0][0]',              \n",
            "                                )                                 'dense_19[0][0]']               \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 300, 300, 16  0           ['conv2d_36[0][0]',              \n",
            "                                )                                 'multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 300, 300, 16  64         ['add_12[0][0]']                 \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 300, 300, 16  0           ['batch_normalization_25[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block_1 (MaxPooling2D)         (None, 150, 150, 16  0           ['activation_21[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 150, 150, 32  544         ['block_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 150, 150, 32  9248        ['conv2d_39[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 150, 150, 32  128        ['conv2d_40[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 150, 150, 32  0           ['batch_normalization_26[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 150, 150, 32  9248        ['activation_22[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " global_average_pooling2d_17 (G  (None, 32)          0           ['conv2d_41[0][0]']              \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_13 (Reshape)           (None, 1, 1, 32)     0           ['global_average_pooling2d_17[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " dense_20 (Dense)               (None, 1, 1, 32)     1056        ['reshape_13[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 150, 150, 32  0           ['conv2d_41[0][0]',              \n",
            "                                )                                 'dense_20[0][0]']               \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 150, 150, 32  0           ['conv2d_39[0][0]',              \n",
            "                                )                                 'multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 150, 150, 32  128        ['add_13[0][0]']                 \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 150, 150, 32  0           ['batch_normalization_27[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block_2 (MaxPooling2D)         (None, 75, 75, 32)   0           ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 75, 75, 64)   2112        ['block_2[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 75, 75, 64)   36928       ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 75, 75, 64)  256         ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 75, 75, 64)   0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 75, 75, 64)   36928       ['activation_24[0][0]']          \n",
            "                                                                                                  \n",
            " global_average_pooling2d_18 (G  (None, 64)          0           ['conv2d_44[0][0]']              \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_14 (Reshape)           (None, 1, 1, 64)     0           ['global_average_pooling2d_18[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " dense_21 (Dense)               (None, 1, 1, 64)     4160        ['reshape_14[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 75, 75, 64)   0           ['conv2d_44[0][0]',              \n",
            "                                                                  'dense_21[0][0]']               \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 75, 75, 64)   0           ['conv2d_42[0][0]',              \n",
            "                                                                  'multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " block_3 (Activation)           (None, 75, 75, 64)   0           ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 75, 75, 64)  256         ['block_3[0][0]']                \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 75, 75, 64)   0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " input2 (InputLayer)            [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " global_average_pooling2d_19 (G  (None, 64)          0           ['dropout_4[0][0]']              \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " dense_22 (Dense)               (None, 16)           32          ['input2[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 80)           0           ['global_average_pooling2d_19[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'dense_22[0][0]']               \n",
            "                                                                                                  \n",
            " dense_23 (Dense)               (None, 240)          19440       ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 125,568\n",
            "Trainable params: 125,120\n",
            "Non-trainable params: 448\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input1 (InputLayer)            [(None, 300, 300, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 300, 300, 16  64          ['input1[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 300, 300, 16  2320        ['conv2d_36[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 300, 300, 16  64         ['conv2d_37[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 300, 300, 16  0           ['batch_normalization_24[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 300, 300, 16  2320        ['activation_20[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " global_average_pooling2d_16 (G  (None, 16)          0           ['conv2d_38[0][0]']              \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_12 (Reshape)           (None, 1, 1, 16)     0           ['global_average_pooling2d_16[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " dense_19 (Dense)               (None, 1, 1, 16)     272         ['reshape_12[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 300, 300, 16  0           ['conv2d_38[0][0]',              \n",
            "                                )                                 'dense_19[0][0]']               \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 300, 300, 16  0           ['conv2d_36[0][0]',              \n",
            "                                )                                 'multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 300, 300, 16  64         ['add_12[0][0]']                 \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 300, 300, 16  0           ['batch_normalization_25[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block_1 (MaxPooling2D)         (None, 150, 150, 16  0           ['activation_21[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 150, 150, 32  544         ['block_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 150, 150, 32  9248        ['conv2d_39[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 150, 150, 32  128        ['conv2d_40[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 150, 150, 32  0           ['batch_normalization_26[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 150, 150, 32  9248        ['activation_22[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " global_average_pooling2d_17 (G  (None, 32)          0           ['conv2d_41[0][0]']              \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_13 (Reshape)           (None, 1, 1, 32)     0           ['global_average_pooling2d_17[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " dense_20 (Dense)               (None, 1, 1, 32)     1056        ['reshape_13[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 150, 150, 32  0           ['conv2d_41[0][0]',              \n",
            "                                )                                 'dense_20[0][0]']               \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 150, 150, 32  0           ['conv2d_39[0][0]',              \n",
            "                                )                                 'multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 150, 150, 32  128        ['add_13[0][0]']                 \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 150, 150, 32  0           ['batch_normalization_27[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block_2 (MaxPooling2D)         (None, 75, 75, 32)   0           ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 75, 75, 64)   2112        ['block_2[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 75, 75, 64)   36928       ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 75, 75, 64)  256         ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 75, 75, 64)   0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 75, 75, 64)   36928       ['activation_24[0][0]']          \n",
            "                                                                                                  \n",
            " global_average_pooling2d_18 (G  (None, 64)          0           ['conv2d_44[0][0]']              \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " reshape_14 (Reshape)           (None, 1, 1, 64)     0           ['global_average_pooling2d_18[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " dense_21 (Dense)               (None, 1, 1, 64)     4160        ['reshape_14[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 75, 75, 64)   0           ['conv2d_44[0][0]',              \n",
            "                                                                  'dense_21[0][0]']               \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 75, 75, 64)   0           ['conv2d_42[0][0]',              \n",
            "                                                                  'multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " block_3 (Activation)           (None, 75, 75, 64)   0           ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 75, 75, 64)  256         ['block_3[0][0]']                \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 75, 75, 64)   0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " input2 (InputLayer)            [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " global_average_pooling2d_19 (G  (None, 64)          0           ['dropout_4[0][0]']              \n",
            " lobalAveragePooling2D)                                                                           \n",
            "                                                                                                  \n",
            " dense_22 (Dense)               (None, 16)           32          ['input2[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 80)           0           ['global_average_pooling2d_19[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'dense_22[0][0]']               \n",
            "                                                                                                  \n",
            " dense_23 (Dense)               (None, 240)          19440       ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 125,568\n",
            "Trainable params: 125,120\n",
            "Non-trainable params: 448\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Adam=tf.keras.optimizers.Adam(lr=0.0001,beta_1=0.9,beta_2=0.999)\n",
        "model.compile(optimizer=Adam, loss='mean_absolute_error', metrics=['MAE'])\n",
        "\n",
        "# Save weights after every epoch\n",
        "#dr='/content/drive/MyDrive/Colab Notebooks/weights'\n",
        "checkpoint =keras.callbacks.ModelCheckpoint(filepath='weights.{epoch:02d}-{val_loss:.2f}.hdf5',save_weights_only=True,period=30)\n",
        "history=model.fit([x_train,gender_train],y_train,batch_size=32,epochs=100,verbose=1,validation_data=([x_valid,gender_valid],y_valid), callbacks = [checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcsG5QcZl9LD",
        "outputId": "f52005fe-e277-4662-8ac5-c1caaf7c55e3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 2s 584ms/step - loss: 0.3537 - MAE: 0.3537 - val_loss: 4.3243 - val_MAE: 4.3243\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 223ms/step - loss: 0.3344 - MAE: 0.3344 - val_loss: 3.0467 - val_MAE: 3.0467\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 227ms/step - loss: 0.3233 - MAE: 0.3233 - val_loss: 2.4235 - val_MAE: 2.4235\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 224ms/step - loss: 0.3154 - MAE: 0.3154 - val_loss: 2.0230 - val_MAE: 2.0230\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 1s 246ms/step - loss: 0.3079 - MAE: 0.3079 - val_loss: 1.7589 - val_MAE: 1.7589\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 1s 238ms/step - loss: 0.3012 - MAE: 0.3012 - val_loss: 1.5538 - val_MAE: 1.5538\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 1s 242ms/step - loss: 0.2961 - MAE: 0.2961 - val_loss: 1.3988 - val_MAE: 1.3988\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 1s 241ms/step - loss: 0.2904 - MAE: 0.2904 - val_loss: 1.2783 - val_MAE: 1.2783\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 1s 235ms/step - loss: 0.2851 - MAE: 0.2851 - val_loss: 1.1747 - val_MAE: 1.1747\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 1s 236ms/step - loss: 0.2809 - MAE: 0.2809 - val_loss: 1.0934 - val_MAE: 1.0934\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 1s 234ms/step - loss: 0.2766 - MAE: 0.2766 - val_loss: 1.0288 - val_MAE: 1.0288\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 1s 240ms/step - loss: 0.2750 - MAE: 0.2750 - val_loss: 0.9731 - val_MAE: 0.9731\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 1s 237ms/step - loss: 0.2699 - MAE: 0.2699 - val_loss: 0.9197 - val_MAE: 0.9197\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 1s 234ms/step - loss: 0.2683 - MAE: 0.2683 - val_loss: 0.8695 - val_MAE: 0.8695\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 228ms/step - loss: 0.2637 - MAE: 0.2637 - val_loss: 0.8214 - val_MAE: 0.8214\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 225ms/step - loss: 0.2644 - MAE: 0.2644 - val_loss: 0.7784 - val_MAE: 0.7784\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 223ms/step - loss: 0.2643 - MAE: 0.2643 - val_loss: 0.7395 - val_MAE: 0.7395\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 226ms/step - loss: 0.2599 - MAE: 0.2599 - val_loss: 0.7056 - val_MAE: 0.7056\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 224ms/step - loss: 0.2570 - MAE: 0.2570 - val_loss: 0.6741 - val_MAE: 0.6741\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 229ms/step - loss: 0.2549 - MAE: 0.2549 - val_loss: 0.6472 - val_MAE: 0.6472\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 219ms/step - loss: 0.2551 - MAE: 0.2551 - val_loss: 0.6229 - val_MAE: 0.6229\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 224ms/step - loss: 0.2516 - MAE: 0.2516 - val_loss: 0.5998 - val_MAE: 0.5998\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 225ms/step - loss: 0.2514 - MAE: 0.2514 - val_loss: 0.5789 - val_MAE: 0.5789\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 225ms/step - loss: 0.2490 - MAE: 0.2490 - val_loss: 0.5598 - val_MAE: 0.5598\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 226ms/step - loss: 0.2473 - MAE: 0.2473 - val_loss: 0.5417 - val_MAE: 0.5417\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 223ms/step - loss: 0.2458 - MAE: 0.2458 - val_loss: 0.5261 - val_MAE: 0.5261\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 226ms/step - loss: 0.2476 - MAE: 0.2476 - val_loss: 0.5121 - val_MAE: 0.5121\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 228ms/step - loss: 0.2439 - MAE: 0.2439 - val_loss: 0.4989 - val_MAE: 0.4989\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 1s 259ms/step - loss: 0.2428 - MAE: 0.2428 - val_loss: 0.4867 - val_MAE: 0.4867\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 1s 291ms/step - loss: 0.2427 - MAE: 0.2427 - val_loss: 0.4749 - val_MAE: 0.4749\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 1s 239ms/step - loss: 0.2410 - MAE: 0.2410 - val_loss: 0.4625 - val_MAE: 0.4625\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 1s 241ms/step - loss: 0.2418 - MAE: 0.2418 - val_loss: 0.4505 - val_MAE: 0.4505\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 1s 242ms/step - loss: 0.2402 - MAE: 0.2402 - val_loss: 0.4395 - val_MAE: 0.4395\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 1s 272ms/step - loss: 0.2379 - MAE: 0.2379 - val_loss: 0.4289 - val_MAE: 0.4289\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 1s 244ms/step - loss: 0.2375 - MAE: 0.2375 - val_loss: 0.4190 - val_MAE: 0.4190\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 1s 238ms/step - loss: 0.2365 - MAE: 0.2365 - val_loss: 0.4102 - val_MAE: 0.4102\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 1s 271ms/step - loss: 0.2356 - MAE: 0.2356 - val_loss: 0.4015 - val_MAE: 0.4015\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 1s 245ms/step - loss: 0.2349 - MAE: 0.2349 - val_loss: 0.3923 - val_MAE: 0.3923\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 231ms/step - loss: 0.2350 - MAE: 0.2350 - val_loss: 0.3825 - val_MAE: 0.3825\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 229ms/step - loss: 0.2345 - MAE: 0.2345 - val_loss: 0.3735 - val_MAE: 0.3735\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 1s 229ms/step - loss: 0.2338 - MAE: 0.2338 - val_loss: 0.3665 - val_MAE: 0.3665\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 231ms/step - loss: 0.2324 - MAE: 0.2324 - val_loss: 0.3601 - val_MAE: 0.3601\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 225ms/step - loss: 0.2324 - MAE: 0.2324 - val_loss: 0.3540 - val_MAE: 0.3540\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 224ms/step - loss: 0.2310 - MAE: 0.2310 - val_loss: 0.3479 - val_MAE: 0.3479\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 1s 259ms/step - loss: 0.2301 - MAE: 0.2301 - val_loss: 0.3417 - val_MAE: 0.3417\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 223ms/step - loss: 0.2299 - MAE: 0.2299 - val_loss: 0.3361 - val_MAE: 0.3361\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 231ms/step - loss: 0.2290 - MAE: 0.2290 - val_loss: 0.3310 - val_MAE: 0.3310\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 1s 230ms/step - loss: 0.2286 - MAE: 0.2286 - val_loss: 0.3257 - val_MAE: 0.3257\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 1s 232ms/step - loss: 0.2284 - MAE: 0.2284 - val_loss: 0.3208 - val_MAE: 0.3208\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 1s 228ms/step - loss: 0.2273 - MAE: 0.2273 - val_loss: 0.3160 - val_MAE: 0.3160\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 1s 232ms/step - loss: 0.2272 - MAE: 0.2272 - val_loss: 0.3120 - val_MAE: 0.3120\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 227ms/step - loss: 0.2264 - MAE: 0.2264 - val_loss: 0.3077 - val_MAE: 0.3077\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 1s 229ms/step - loss: 0.2258 - MAE: 0.2258 - val_loss: 0.3043 - val_MAE: 0.3043\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 226ms/step - loss: 0.2260 - MAE: 0.2260 - val_loss: 0.3001 - val_MAE: 0.3001\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 226ms/step - loss: 0.2245 - MAE: 0.2245 - val_loss: 0.2966 - val_MAE: 0.2966\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 1s 229ms/step - loss: 0.2242 - MAE: 0.2242 - val_loss: 0.2932 - val_MAE: 0.2932\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 1s 230ms/step - loss: 0.2250 - MAE: 0.2250 - val_loss: 0.2906 - val_MAE: 0.2906\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 1s 231ms/step - loss: 0.2253 - MAE: 0.2253 - val_loss: 0.2886 - val_MAE: 0.2886\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 1s 265ms/step - loss: 0.2229 - MAE: 0.2229 - val_loss: 0.2855 - val_MAE: 0.2855\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 1s 266ms/step - loss: 0.2235 - MAE: 0.2235 - val_loss: 0.2823 - val_MAE: 0.2823\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 1s 242ms/step - loss: 0.2222 - MAE: 0.2222 - val_loss: 0.2791 - val_MAE: 0.2791\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 1s 275ms/step - loss: 0.2219 - MAE: 0.2219 - val_loss: 0.2765 - val_MAE: 0.2765\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 226ms/step - loss: 0.2210 - MAE: 0.2210 - val_loss: 0.2737 - val_MAE: 0.2737\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 228ms/step - loss: 0.2208 - MAE: 0.2208 - val_loss: 0.2716 - val_MAE: 0.2716\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 229ms/step - loss: 0.2204 - MAE: 0.2204 - val_loss: 0.2703 - val_MAE: 0.2703\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 1s 260ms/step - loss: 0.2200 - MAE: 0.2200 - val_loss: 0.2685 - val_MAE: 0.2685\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 1s 265ms/step - loss: 0.2198 - MAE: 0.2198 - val_loss: 0.2666 - val_MAE: 0.2666\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 1s 231ms/step - loss: 0.2190 - MAE: 0.2190 - val_loss: 0.2642 - val_MAE: 0.2642\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 1s 232ms/step - loss: 0.2193 - MAE: 0.2193 - val_loss: 0.2626 - val_MAE: 0.2626\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 228ms/step - loss: 0.2194 - MAE: 0.2194 - val_loss: 0.2609 - val_MAE: 0.2609\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 228ms/step - loss: 0.2179 - MAE: 0.2179 - val_loss: 0.2597 - val_MAE: 0.2597\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 225ms/step - loss: 0.2184 - MAE: 0.2184 - val_loss: 0.2590 - val_MAE: 0.2590\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 231ms/step - loss: 0.2174 - MAE: 0.2174 - val_loss: 0.2581 - val_MAE: 0.2581\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 226ms/step - loss: 0.2175 - MAE: 0.2175 - val_loss: 0.2569 - val_MAE: 0.2569\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 1s 234ms/step - loss: 0.2182 - MAE: 0.2182 - val_loss: 0.2562 - val_MAE: 0.2562\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 229ms/step - loss: 0.2162 - MAE: 0.2162 - val_loss: 0.2542 - val_MAE: 0.2542\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 1s 238ms/step - loss: 0.2160 - MAE: 0.2160 - val_loss: 0.2521 - val_MAE: 0.2521\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 1s 259ms/step - loss: 0.2154 - MAE: 0.2154 - val_loss: 0.2512 - val_MAE: 0.2512\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 1s 263ms/step - loss: 0.2151 - MAE: 0.2151 - val_loss: 0.2512 - val_MAE: 0.2512\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 223ms/step - loss: 0.2151 - MAE: 0.2151 - val_loss: 0.2513 - val_MAE: 0.2513\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 227ms/step - loss: 0.2151 - MAE: 0.2151 - val_loss: 0.2507 - val_MAE: 0.2507\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 226ms/step - loss: 0.2145 - MAE: 0.2145 - val_loss: 0.2491 - val_MAE: 0.2491\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 1s 229ms/step - loss: 0.2147 - MAE: 0.2147 - val_loss: 0.2475 - val_MAE: 0.2475\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 227ms/step - loss: 0.2135 - MAE: 0.2135 - val_loss: 0.2467 - val_MAE: 0.2467\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 1s 233ms/step - loss: 0.2140 - MAE: 0.2140 - val_loss: 0.2464 - val_MAE: 0.2464\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 1s 256ms/step - loss: 0.2154 - MAE: 0.2154 - val_loss: 0.2464 - val_MAE: 0.2464\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 228ms/step - loss: 0.2132 - MAE: 0.2132 - val_loss: 0.2448 - val_MAE: 0.2448\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 229ms/step - loss: 0.2128 - MAE: 0.2128 - val_loss: 0.2437 - val_MAE: 0.2437\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 1s 239ms/step - loss: 0.2143 - MAE: 0.2143 - val_loss: 0.2430 - val_MAE: 0.2430\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 1s 272ms/step - loss: 0.2125 - MAE: 0.2125 - val_loss: 0.2431 - val_MAE: 0.2431\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 1s 245ms/step - loss: 0.2121 - MAE: 0.2121 - val_loss: 0.2431 - val_MAE: 0.2431\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 1s 282ms/step - loss: 0.2115 - MAE: 0.2115 - val_loss: 0.2426 - val_MAE: 0.2426\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 1s 246ms/step - loss: 0.2114 - MAE: 0.2114 - val_loss: 0.2417 - val_MAE: 0.2417\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 1s 247ms/step - loss: 0.2114 - MAE: 0.2114 - val_loss: 0.2412 - val_MAE: 0.2412\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 1s 435ms/step - loss: 0.2110 - MAE: 0.2110 - val_loss: 0.2412 - val_MAE: 0.2412\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 1s 252ms/step - loss: 0.2107 - MAE: 0.2107 - val_loss: 0.2408 - val_MAE: 0.2408\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.2106 - MAE: 0.2106 - val_loss: 0.2405 - val_MAE: 0.2405\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 1s 318ms/step - loss: 0.2102 - MAE: 0.2102 - val_loss: 0.2394 - val_MAE: 0.2394\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 1s 235ms/step - loss: 0.2105 - MAE: 0.2105 - val_loss: 0.2393 - val_MAE: 0.2393\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 1s 242ms/step - loss: 0.2096 - MAE: 0.2096 - val_loss: 0.2396 - val_MAE: 0.2396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "ciJNdA4mm6ft",
        "outputId": "5642ff51-2726-4212-b61f-c5b96254e2d9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "XELI49YcnSKV",
        "outputId": "d7b7d460-210e-48cb-f7ab-88ca21821e30"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EkiHcB0fx0Hd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "U_net.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPWRjaD80r2R/wClAHQou/9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bone-Age-Maisha/paper_1/blob/main/U_net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "J6rR2tUNzHsD",
        "outputId": "d98e9a3a-6d77-4589-a305-ed9c26987798"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "metadata": {
        "id": "JL-rYC7KzUwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZ9U5W3Yzi04",
        "outputId": "73984d6c-47bd-40a5-dbf7-c3611aaf0800"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_dir = '/content/drive/MyDrive/small_data/train'\n",
        "df = pd.read_csv('/content/drive/MyDrive/small_data/train_csv1.csv')"
      ],
      "metadata": {
        "id": "zkUPiojA0TwO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ///from Attention model data preparation///"
      ],
      "metadata": {
        "id": "9JSb-GTy3V9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import pandas as pd\n",
        "from six.moves import cPickle"
      ],
      "metadata": {
        "id": "sLY3WmYm3snt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "y_age = []\n",
        "y_gender = []\n",
        "\n",
        "#df = pd.read_csv('/raid/chenchao/code/BoneAge/BoneAge/data/Training.csv')\n",
        "a = df.values\n",
        "m = a.shape[0]\n",
        "\n",
        "cnt=1\n",
        "path = train_dir\n",
        "k = 0\n",
        "print ('Loading data set...')\n",
        "k=1\n",
        "for i in os.listdir(path):\n",
        "  #print(i)\n",
        "  print(cnt)\n",
        "  cnt=cnt+1\n",
        "  if(len(i)>9):   #errror occuring  so to \n",
        "    continue\n",
        "  y_age.append(df.boneage[df.id == int(i[:-4])].tolist()[0])\n",
        "  a = df.male[df.id == int(i[:-4])].tolist()[0]\n",
        "  if a:\n",
        "    y_gender.append(1)\n",
        "  else:\n",
        "     y_gender.append(0)\n",
        "  img_path = path + \"/\"+i\n",
        "  img = cv2.imread(img_path)\n",
        "  #print(img.shape)\n",
        "  print (img_path)\n",
        "  img = cv2.imread(img_path)\n",
        "    #print (img_path)\n",
        "    #if(img is not None):\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  #img = cv2.resize(img,(1514,2044))\n",
        "  img = cv2.resize(img,(256,256))\n",
        "  x = np.asarray(img, dtype=np.uint8)\n",
        "  X_train.append(x)\n",
        "    \n",
        "print ('100% completed loading data')\n",
        "\n",
        "# Save data\n",
        "train_pkl = open('data.pkl','wb')\n",
        "cPickle.dump(X_train, train_pkl, protocol=cPickle.HIGHEST_PROTOCOL)\n",
        "train_pkl.close()\n",
        "\n",
        "train_age_pkl = open('data_age.pkl','wb')\n",
        "cPickle.dump(y_age, train_age_pkl, protocol=cPickle.HIGHEST_PROTOCOL)\n",
        "train_age_pkl.close()\n",
        "\n",
        "train_gender_pkl = open('data_gender.pkl','wb')\n",
        "cPickle.dump(y_gender, train_gender_pkl, protocol=cPickle.HIGHEST_PROTOCOL)\n",
        "train_gender_pkl.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "z89jQTDGBcQE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "328f6f83-245d-42d8-ad38-da8d9b592e64"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data set...\n",
            "1\n",
            "/content/drive/MyDrive/small_data/train/1378.png\n",
            "2\n",
            "/content/drive/MyDrive/small_data/train/1377.png\n",
            "3\n",
            "/content/drive/MyDrive/small_data/train/1379.png\n",
            "4\n",
            "/content/drive/MyDrive/small_data/train/1380.png\n",
            "5\n",
            "/content/drive/MyDrive/small_data/train/1381.png\n",
            "6\n",
            "/content/drive/MyDrive/small_data/train/1385.png\n",
            "7\n",
            "/content/drive/MyDrive/small_data/train/1383.png\n",
            "8\n",
            "/content/drive/MyDrive/small_data/train/1384.png\n",
            "9\n",
            "/content/drive/MyDrive/small_data/train/1382.png\n",
            "10\n",
            "/content/drive/MyDrive/small_data/train/1387.png\n",
            "11\n",
            "/content/drive/MyDrive/small_data/train/1388.png\n",
            "12\n",
            "/content/drive/MyDrive/small_data/train/1390.png\n",
            "13\n",
            "/content/drive/MyDrive/small_data/train/1391.png\n",
            "14\n",
            "/content/drive/MyDrive/small_data/train/1389.png\n",
            "15\n",
            "/content/drive/MyDrive/small_data/train/1395.png\n",
            "16\n",
            "/content/drive/MyDrive/small_data/train/1393.png\n",
            "17\n",
            "/content/drive/MyDrive/small_data/train/1394.png\n",
            "18\n",
            "/content/drive/MyDrive/small_data/train/1399.png\n",
            "19\n",
            "/content/drive/MyDrive/small_data/train/1398.png\n",
            "20\n",
            "/content/drive/MyDrive/small_data/train/1396.png\n",
            "21\n",
            "/content/drive/MyDrive/small_data/train/1402.png\n",
            "22\n",
            "/content/drive/MyDrive/small_data/train/1403.png\n",
            "23\n",
            "/content/drive/MyDrive/small_data/train/1400.png\n",
            "24\n",
            "/content/drive/MyDrive/small_data/train/1406.png\n",
            "25\n",
            "/content/drive/MyDrive/small_data/train/1405.png\n",
            "26\n",
            "/content/drive/MyDrive/small_data/train/1404.png\n",
            "27\n",
            "/content/drive/MyDrive/small_data/train/1408.png\n",
            "28\n",
            "/content/drive/MyDrive/small_data/train/1409.png\n",
            "29\n",
            "/content/drive/MyDrive/small_data/train/1407.png\n",
            "30\n",
            "/content/drive/MyDrive/small_data/train/1411.png\n",
            "31\n",
            "/content/drive/MyDrive/small_data/train/1412.png\n",
            "32\n",
            "/content/drive/MyDrive/small_data/train/1414.png\n",
            "33\n",
            "/content/drive/MyDrive/small_data/train/1416.png\n",
            "34\n",
            "/content/drive/MyDrive/small_data/train/1415.png\n",
            "35\n",
            "/content/drive/MyDrive/small_data/train/1419.png\n",
            "36\n",
            "/content/drive/MyDrive/small_data/train/1418.png\n",
            "37\n",
            "/content/drive/MyDrive/small_data/train/1417.png\n",
            "38\n",
            "/content/drive/MyDrive/small_data/train/1420.png\n",
            "39\n",
            "/content/drive/MyDrive/small_data/train/1423.png\n",
            "40\n",
            "/content/drive/MyDrive/small_data/train/1424.png\n",
            "41\n",
            "/content/drive/MyDrive/small_data/train/1422.png\n",
            "42\n",
            "/content/drive/MyDrive/small_data/train/1426.png\n",
            "43\n",
            "/content/drive/MyDrive/small_data/train/1427.png\n",
            "44\n",
            "/content/drive/MyDrive/small_data/train/1425.png\n",
            "45\n",
            "/content/drive/MyDrive/small_data/train/1429.png\n",
            "46\n",
            "/content/drive/MyDrive/small_data/train/1428.png\n",
            "47\n",
            "/content/drive/MyDrive/small_data/train/1430.png\n",
            "48\n",
            "/content/drive/MyDrive/small_data/train/1433.png\n",
            "49\n",
            "/content/drive/MyDrive/small_data/train/1434.png\n",
            "50\n",
            "/content/drive/MyDrive/small_data/train/1431.png\n",
            "51\n",
            "/content/drive/MyDrive/small_data/train/1432.png\n",
            "52\n",
            "/content/drive/MyDrive/small_data/train/1435.png\n",
            "53\n",
            "/content/drive/MyDrive/small_data/train/1437.png\n",
            "54\n",
            "/content/drive/MyDrive/small_data/train/1436.png\n",
            "55\n",
            "/content/drive/MyDrive/small_data/train/1439.png\n",
            "56\n",
            "/content/drive/MyDrive/small_data/train/1438.png\n",
            "57\n",
            "/content/drive/MyDrive/small_data/train/1440.png\n",
            "58\n",
            "/content/drive/MyDrive/small_data/train/1443.png\n",
            "59\n",
            "/content/drive/MyDrive/small_data/train/1442.png\n",
            "60\n",
            "/content/drive/MyDrive/small_data/train/1441.png\n",
            "61\n",
            "/content/drive/MyDrive/small_data/train/1445.png\n",
            "62\n",
            "/content/drive/MyDrive/small_data/train/1444.png\n",
            "63\n",
            "/content/drive/MyDrive/small_data/train/1446.png\n",
            "64\n",
            "/content/drive/MyDrive/small_data/train/1447.png\n",
            "65\n",
            "/content/drive/MyDrive/small_data/train/1448.png\n",
            "66\n",
            "/content/drive/MyDrive/small_data/train/1453.png\n",
            "67\n",
            "/content/drive/MyDrive/small_data/train/1451.png\n",
            "68\n",
            "/content/drive/MyDrive/small_data/train/1452.png\n",
            "69\n",
            "/content/drive/MyDrive/small_data/train/1454.png\n",
            "70\n",
            "/content/drive/MyDrive/small_data/train/1455.png\n",
            "71\n",
            "/content/drive/MyDrive/small_data/train/1457.png\n",
            "72\n",
            "100% completed loading data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def SaveImg(filename,filepath,heatmap):\n",
        "    img = cv2.imread(filepath)\n",
        "    heatmap = cv2.resize(heatmap,(img.shape[1],img.shape[0]))\n",
        "    AttentionImg =0.5* heatmap + img\n",
        "    cv2.imwrite('/content/heat'+filename,heatmap)\n",
        "    cv2.imwrite('/content/attention'+filename,AttentionImg)\n",
        "\n",
        "\n",
        "def load_image(path):\n",
        "    img = cv2.imread(path)\n",
        "    #print(img.shape)\n",
        "    #img = cv2.resize(img,(256,256))   ##my own edit\n",
        "    print(img.shape)\n",
        "    x = np.asarray(img, dtype=np.float32)\n",
        "   # img = image.load_img(path, target_size=(448, 448))\n",
        "   # print (img.shape)\n",
        "   # x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def softlabel(label,num_class):\n",
        "    softlabel=np.zeros((len(label),num_class))\n",
        "    ratio = 1.0/50\n",
        "    for i in range(len(label)):\n",
        "        for j in range(num_class):\n",
        "            softlabel[i,j]=1.0 - ratio*np.abs(j-label[i])\n",
        "    softlabel = np.maximum(softlabel,0)\n",
        "    return softlabel\n",
        "\n",
        "\n",
        "\n",
        "def GaussLabel(label,num_class):\n",
        "    sigma=15.0\n",
        "    GaussLabel = np.zeros((len(label),num_class))\n",
        "    x = np.array(range(num_class))+1\n",
        "    for k in range(len(label)):\n",
        "        GaussLabel[k,:]=np.exp(-(x-label[k])**2/(2.0*sigma**2))\n",
        "    return GaussLabel\n",
        "\n",
        "\n",
        "def TestMAE(model,test_data,test_label,test_gender):\n",
        "    test_gender = np.array(test_gender)\n",
        "    test_gender = np.expand_dims(test_gender,axis=1)\n",
        "    layer=K.function([model.layers[0].input,model.layers[3].input],[model.layers[-1].output])\n",
        "    predictions=layer([test_data,test_gender])\n",
        "    predictions = np.array(predictions)\n",
        "    predictions = np.squeeze(predictions,axis=0)\n",
        "    print (predictions.shape)\n",
        "    predict_label = np.argmax(predictions,axis=1)\n",
        "    test_label = np.argmax(test_label,axis=1)\n",
        "    print (predict_label)\n",
        "    print (test_label)\n",
        "    TestMAE = np.mean(np.abs(predict_label-test_label))\n",
        "    return TestMAE\n",
        "\n"
      ],
      "metadata": {
        "id": "q8bLrWYVz-yd"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.xception import Xception\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Flatten, Dense, Input, Reshape, Lambda\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "#from func_utils import *\n",
        "import os\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
        "#os.environ['OMP_NUM_THREADS']='6'\n",
        "batch_size = 32\n",
        "epochs = 30\n",
        "\n",
        "# Load data\n",
        "print('...loading training data')\n",
        "f = open('/content/data.pkl', 'rb')\n",
        "x = pickle.load(f)\n",
        "f.close()\n",
        "\n",
        "f = open('/content/data_age.pkl', 'rb')\n",
        "y = pickle.load(f)\n",
        "f.close()\n",
        "\n",
        "f = open('/content/data_gender.pkl','rb')\n",
        "gender = pickle.load(f)\n",
        "f.close()\n",
        "\n",
        "print(len(x[0]))\n",
        "print(len(x[1]))\n",
        "print(len(x[2]))\n",
        "\n",
        "x = np.asarray(x, dtype=np.float32)\n",
        "y = np.asarray(y)\n",
        "gender = np.asarray(gender)\n",
        "\n",
        "x /= 255.\n",
        "gender =2*( gender-0.5)\n",
        "x_final = []\n",
        "y_final = []\n",
        "gender_final = []\n",
        "\n",
        "# Shuffle images and split into train, validation and test sets\n",
        "#random_no = np.random.choice(x.shape[0], size=x.shape[0], replace=False)\n",
        "random_no = np.arange(x.shape[0])\n",
        "#print(random_no)\n",
        "np.random.seed(0)\n",
        "np.random.shuffle(random_no)\n",
        "for i in random_no:\n",
        "    x_final.append(x[i,:,:,:])\n",
        "    y_final.append(y[i])\n",
        "    gender_final.append(gender[i])\n",
        "\n",
        "x_final = np.asarray(x_final)\n",
        "y_final = np.asarray(y_final)\n",
        "gender_final = np.asarray(gender_final)\n",
        "print (y_final[:50])\n",
        "print (gender_final[:50])\n",
        "k = 10 # Decides split count\n",
        "x_test = x_final[:k,:,:,:]\n",
        "y_test = y_final[:k]\n",
        "gender_test = gender_final[:k]\n",
        "x_valid = x_final[k:2*k,:,:,:]\n",
        "y_valid = y_final[k:2*k]\n",
        "gender_valid = gender_final[k:2*k]\n",
        "x_train = x_final[2*k:,:,:,:]\n",
        "y_train = y_final[2*k:]\n",
        "gender_train = gender_final[2*k:]\n",
        "\n",
        "## \n",
        "#y_test = keras.utils.to_categorical(y_test,240)\n",
        "#y_train = keras.utils.to_categorical(y_train,240)\n",
        "#y_valid = keras.utils.to_categorical(y_valid,240)\n",
        "y_train = softlabel(y_train,240)\n",
        "y_valid = softlabel(y_valid,240)\n",
        "y_test = softlabel(y_test,240)\n",
        "print (y_train)\n",
        "\n",
        "\n",
        "print ('x_train shape:'+ str(x_train.shape))\n",
        "print ('y_train shape:'+ str(y_train.shape))\n",
        "print ('gender_train shape:'+ str(gender_train.shape))\n",
        "print ('x_valid shape:'+ str(x_valid.shape))\n",
        "print ('y_valid shape:'+ str(y_valid.shape))\n",
        "print ('gender_valid shape:' + str(gender_valid.shape))\n",
        "print ('x_test shape:'+ str(x_test.shape))\n",
        "print ('y_test shape:'+ str(y_test.shape))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIUzuP0y0Ikf",
        "outputId": "5a3093c5-5dcd-4aa1-b13c-48cd63ba088a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...loading training data\n",
            "256\n",
            "256\n",
            "256\n",
            "[126 149 113 132 156 180 156  42 126 126  42  30  78 174  88 165  32 132\n",
            " 156  82 192 170  94  32 156 120  60  33 126  54  27 108  94 162 120  21\n",
            " 188  33 136  24   4  12 132  36  57  24  90 138 138 159]\n",
            "[ 1.  1. -1. -1. -1.  1.  1. -1.  1. -1.  1. -1.  1.  1. -1.  1.  1.  1.\n",
            "  1. -1.  1.  1. -1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1. -1.  1.  1. -1.  1.  1.  1. -1.]\n",
            "[[0.   0.   0.   ... 0.1  0.08 0.06]\n",
            " [0.   0.   0.   ... 0.   0.   0.  ]\n",
            " [0.   0.   0.   ... 0.   0.   0.  ]\n",
            " ...\n",
            " [0.   0.02 0.04 ... 0.   0.   0.  ]\n",
            " [0.52 0.54 0.56 ... 0.   0.   0.  ]\n",
            " [0.   0.   0.   ... 0.   0.   0.  ]]\n",
            "x_train shape:(51, 256, 256, 3)\n",
            "y_train shape:(51, 240)\n",
            "gender_train shape:(51,)\n",
            "x_valid shape:(10, 256, 256, 3)\n",
            "y_valid shape:(10, 240)\n",
            "gender_valid shape:(10,)\n",
            "x_test shape:(10, 256, 256, 3)\n",
            "y_test shape:(10, 240)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UNet to compress image"
      ],
      "metadata": {
        "id": "fjM7GQj89Tj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import os\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "import numpy as np\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras import backend as keras\n",
        "\n",
        "\n",
        "def unet(pretrained_weights = None,input_size = (256,256,3)):\n",
        "    inputs = Input(input_size)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "    #conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "    #conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "    #conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "    #conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "    #pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "    #conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
        "    merge6 = concatenate([drop4,up6], axis = 3)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "\n",
        "    up7 = Conv2D(256,2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "    merge7 = concatenate([conv3,up7], axis = 3)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "\n",
        "    #up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "    #merge8 = concatenate([conv2,up8], axis = 3)\n",
        "    #conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "    #conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "\n",
        "    #up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "    #merge9 = concatenate([conv1,up9], axis = 3)\n",
        "    #conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
        "    #conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    #conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    #conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
        "\n",
        "    #model = Model(input = inputs, output = conv10)\n",
        "    model = Model(inputs = inputs, outputs = conv7)\n",
        "\n",
        "    Adam=tf.keras.optimizers.Adam(lr=0.0001)\n",
        "    model.compile(optimizer=Adam, loss='mean_absolute_error', metrics=['MAE'])\n",
        "    #model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "    model.summary()\n",
        "\n",
        "    if(pretrained_weights):\n",
        "    \tmodel.load_weights(pretrained_weights)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "L-dDquWV9Z3D"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Raw_copy"
      ],
      "metadata": {
        "id": "pW-eFX38EMX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "    merge7 = concatenate([conv3,up7], axis = 3)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "\n",
        "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "    merge8 = concatenate([conv2,up8], axis = 3)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "\n",
        "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "    merge9 = concatenate([conv1,up9], axis = 3)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n"
      ],
      "metadata": {
        "id": "1A3cMteTHueU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unet(pretrained_weights = None,input_size = (256,256,3)):\n",
        "    inputs = Input(input_size)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
        "    merge6 = concatenate([drop4,up6], axis = 3)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "\n",
        "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "    merge7 = concatenate([conv3,up7], axis = 3)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "\n",
        "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "    merge8 = concatenate([conv2,up8], axis = 3)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "\n",
        "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "    merge9 = concatenate([conv1,up9], axis = 3)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv9 = tf.keras.layers.GlobalAveragePooling2D()(conv9)\n",
        "    conv10 = tf.keras.layers.Dense(1)(conv9)\n",
        "\n",
        "    model = Model(inputs = inputs, outputs = conv10)\n",
        "\n",
        "    Adam=tf.keras.optimizers.Adam(lr=0.0001)\n",
        "    model.compile(optimizer=Adam, loss='mean_absolute_error', metrics=['MAE'])\n",
        "    #model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "    model.summary()\n",
        "\n",
        "    if(pretrained_weights):\n",
        "    \tmodel.load_weights(pretrained_weights)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "4ETo2XfEELkD"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = unet()\n",
        "model_checkpoint = ModelCheckpoint('unet_membrane.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
        "model.fit(x_train,y_train,epochs=10,steps_per_epoch=5,callbacks=[model_checkpoint])\n",
        "#model.fit_generator(myGene,steps_per_epoch=300,epochs=1,callbacks=[model_checkpoint])\n",
        "\n",
        "#testGene = testGenerator(\"data/membrane/test\")\n",
        "#results = model.predict_generator(testGene,30,verbose=1)\n",
        "#saveResult(\"data/membrane/test\",results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1YcbP6K_xp6",
        "outputId": "98902e1e-54b2-4190-f21a-1065f387a735"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_15 (InputLayer)          [(None, 256, 256, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_275 (Conv2D)            (None, 256, 256, 64  1792        ['input_15[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_276 (Conv2D)            (None, 256, 256, 64  36928       ['conv2d_275[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_56 (MaxPooling2D  (None, 128, 128, 64  0          ['conv2d_276[0][0]']             \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_277 (Conv2D)            (None, 128, 128, 12  73856       ['max_pooling2d_56[0][0]']       \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_278 (Conv2D)            (None, 128, 128, 12  147584      ['conv2d_277[0][0]']             \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_57 (MaxPooling2D  (None, 64, 64, 128)  0          ['conv2d_278[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_279 (Conv2D)            (None, 64, 64, 256)  295168      ['max_pooling2d_57[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_280 (Conv2D)            (None, 64, 64, 256)  590080      ['conv2d_279[0][0]']             \n",
            "                                                                                                  \n",
            " max_pooling2d_58 (MaxPooling2D  (None, 32, 32, 256)  0          ['conv2d_280[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_281 (Conv2D)            (None, 32, 32, 512)  1180160     ['max_pooling2d_58[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_282 (Conv2D)            (None, 32, 32, 512)  2359808     ['conv2d_281[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_28 (Dropout)           (None, 32, 32, 512)  0           ['conv2d_282[0][0]']             \n",
            "                                                                                                  \n",
            " max_pooling2d_59 (MaxPooling2D  (None, 16, 16, 512)  0          ['dropout_28[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_283 (Conv2D)            (None, 16, 16, 1024  4719616     ['max_pooling2d_59[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_284 (Conv2D)            (None, 16, 16, 1024  9438208     ['conv2d_283[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_29 (Dropout)           (None, 16, 16, 1024  0           ['conv2d_284[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d_32 (UpSampling2D  (None, 32, 32, 1024  0          ['dropout_29[0][0]']             \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_285 (Conv2D)            (None, 32, 32, 512)  2097664     ['up_sampling2d_32[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_32 (Concatenate)   (None, 32, 32, 1024  0           ['dropout_28[0][0]',             \n",
            "                                )                                 'conv2d_285[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_286 (Conv2D)            (None, 32, 32, 512)  4719104     ['concatenate_32[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_287 (Conv2D)            (None, 32, 32, 512)  2359808     ['conv2d_286[0][0]']             \n",
            "                                                                                                  \n",
            " up_sampling2d_33 (UpSampling2D  (None, 64, 64, 512)  0          ['conv2d_287[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_288 (Conv2D)            (None, 64, 64, 256)  524544      ['up_sampling2d_33[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_33 (Concatenate)   (None, 64, 64, 512)  0           ['conv2d_280[0][0]',             \n",
            "                                                                  'conv2d_288[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_289 (Conv2D)            (None, 64, 64, 256)  1179904     ['concatenate_33[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_290 (Conv2D)            (None, 64, 64, 256)  590080      ['conv2d_289[0][0]']             \n",
            "                                                                                                  \n",
            " up_sampling2d_34 (UpSampling2D  (None, 128, 128, 25  0          ['conv2d_290[0][0]']             \n",
            " )                              6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_291 (Conv2D)            (None, 128, 128, 12  131200      ['up_sampling2d_34[0][0]']       \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_34 (Concatenate)   (None, 128, 128, 25  0           ['conv2d_278[0][0]',             \n",
            "                                6)                                'conv2d_291[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_292 (Conv2D)            (None, 128, 128, 12  295040      ['concatenate_34[0][0]']         \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_293 (Conv2D)            (None, 128, 128, 12  147584      ['conv2d_292[0][0]']             \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " up_sampling2d_35 (UpSampling2D  (None, 256, 256, 12  0          ['conv2d_293[0][0]']             \n",
            " )                              8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_294 (Conv2D)            (None, 256, 256, 64  32832       ['up_sampling2d_35[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_35 (Concatenate)   (None, 256, 256, 12  0           ['conv2d_276[0][0]',             \n",
            "                                8)                                'conv2d_294[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_295 (Conv2D)            (None, 256, 256, 64  73792       ['concatenate_35[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_296 (Conv2D)            (None, 256, 256, 64  36928       ['conv2d_295[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_297 (Conv2D)            (None, 256, 256, 2)  1154        ['conv2d_296[0][0]']             \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 2)           0           ['conv2d_297[0][0]']             \n",
            " alAveragePooling2D)                                                                              \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1)            3           ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31,032,837\n",
            "Trainable params: 31,032,837\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2027 - MAE: 0.2027\n",
            "Epoch 1: loss improved from inf to 0.20268, saving model to unet_membrane.hdf5\n",
            "5/5 [==============================] - 32s 3s/step - loss: 0.2027 - MAE: 0.2027\n",
            "Epoch 2/10\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2012 - MAE: 0.2012\n",
            "Epoch 2: loss improved from 0.20268 to 0.20122, saving model to unet_membrane.hdf5\n",
            "5/5 [==============================] - 5s 1s/step - loss: 0.2012 - MAE: 0.2012\n",
            "Epoch 3/10\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2012 - MAE: 0.2012\n",
            "Epoch 3: loss improved from 0.20122 to 0.20119, saving model to unet_membrane.hdf5\n",
            "5/5 [==============================] - 5s 1s/step - loss: 0.2012 - MAE: 0.2012\n",
            "Epoch 4/10\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2012 - MAE: 0.2012\n",
            "Epoch 4: loss did not improve from 0.20119\n",
            "5/5 [==============================] - 3s 656ms/step - loss: 0.2012 - MAE: 0.2012\n",
            "Epoch 5/10\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2012 - MAE: 0.2012\n",
            "Epoch 5: loss improved from 0.20119 to 0.20118, saving model to unet_membrane.hdf5\n",
            "5/5 [==============================] - 5s 1s/step - loss: 0.2012 - MAE: 0.2012\n",
            "Epoch 6/10\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2012 - MAE: 0.2012\n",
            "Epoch 6: loss did not improve from 0.20118\n",
            "5/5 [==============================] - 3s 659ms/step - loss: 0.2012 - MAE: 0.2012\n",
            "Epoch 7/10\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2012 - MAE: 0.2012\n",
            "Epoch 7: loss did not improve from 0.20118\n",
            "5/5 [==============================] - 3s 655ms/step - loss: 0.2012 - MAE: 0.2012\n",
            "Epoch 8/10\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2012 - MAE: 0.2012\n",
            "Epoch 8: loss did not improve from 0.20118\n",
            "5/5 [==============================] - 3s 659ms/step - loss: 0.2012 - MAE: 0.2012\n",
            "Epoch 9/10\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2012 - MAE: 0.2012\n",
            "Epoch 9: loss improved from 0.20118 to 0.20117, saving model to unet_membrane.hdf5\n",
            "5/5 [==============================] - 5s 976ms/step - loss: 0.2012 - MAE: 0.2012\n",
            "Epoch 10/10\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2012 - MAE: 0.2012\n",
            "Epoch 10: loss improved from 0.20117 to 0.20117, saving model to unet_membrane.hdf5\n",
            "5/5 [==============================] - 5s 1s/step - loss: 0.2012 - MAE: 0.2012\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbb6a4e5210>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(\"unet_membrane.hdf5\")\n",
        "score = model.evaluate(x_test, y_test,2)\n",
        "print('Test loss:', score[0])\n",
        "print('Test MAE:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gn07DYoJ7ak",
        "outputId": "b18189f8-fb12-417d-bcf5-6527bc825c26"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 2s 54ms/step - loss: 0.2081 - MAE: 0.2081\n",
            "Test loss: 0.20810022950172424\n",
            "Test MAE: 0.20810022950172424\n"
          ]
        }
      ]
    }
  ]
}